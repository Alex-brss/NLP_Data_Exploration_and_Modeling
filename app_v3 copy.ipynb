{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow_hub/__init__.py:61: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import parse_version\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:121: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"best_of\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:140: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"repetition_penalty\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:146: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"seed\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:152: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"temperature\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:158: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"top_k\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:164: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"top_p\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:170: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"truncate\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:176: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"typical_p\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:204: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"inputs\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:210: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"stream\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gensim.downloader as api\n",
    "import tensorflow_hub as hub\n",
    "import nlpaug.augmenter.word as naw\n",
    "import random\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoTokenizer\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, Word2Vec, KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorboard.plugins import projector\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from tensorboard.plugins import projector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nlpaug.util import Action\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Functions ---------- #\n",
    "\n",
    "# ---------- Loading the dataset ---------- #\n",
    "\n",
    "df = pd.read_csv('yelp_reviews.csv')\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['text', 'rating', 'location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Preprocessing ---------- #\n",
    "\n",
    "# Translation pipeline\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Check if text contains Chinese characters\n",
    "def contains_chinese(text):\n",
    "    return bool(re.search('[\\u4e00-\\u9fff]', text))\n",
    "\n",
    "# Translation function (from Chinese to English)\n",
    "def translate_text(text):\n",
    "    if contains_chinese(text):\n",
    "        return translator(text)[0]['translation_text']\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "# Lemmatisation & Tokenisation function\n",
    "def tokenisation(reviews, allowed_postags=[\"NOUN\", \"ADJ\", \"VERBS\", \"ADV\"]):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "    reviews_out = []\n",
    "    tokens = []\n",
    "\n",
    "    for review in reviews:\n",
    "        doc = nlp(review) \n",
    "        reviews_out.append(\" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags and token.lemma_ not in stop_words]))\n",
    "    \n",
    "    for text in reviews_out:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=False) # We do not remove the accent marks because we deem them important for French restaurants reviews\n",
    "        tokens.append(new)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(text):\n",
    "    # Corrected spelling on lower case text\n",
    "    corrected_text = str(TextBlob(text.lower()).correct())\n",
    "\n",
    "    # Translation\n",
    "    cleaned_text = translate_text(str(corrected_text))\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing and tokenisation\n",
    "df['cleaned_text'] = df['text'].apply(preprocessing)\n",
    "df['tokens'] = tokenisation(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarisation\n",
    "\n",
    "max_length_coef = 1.5\n",
    "min_length_coef = 2\n",
    "\n",
    "summariser = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summarised_text = df['text'].apply(lambda x: summariser(x, max_length=round(len(x)/max_length_coef), min_length=round(len(x)/min_length_coef), do_sample=False))\n",
    "df['summarised_text'] = summarised_text.apply(lambda x: x[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq</th>\n",
       "      <th>bigram_freq</th>\n",
       "      <th>trigram_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'[': 10, ''': 204, 'a': 41, 'm': 17, 'z': 2, ...</td>\n",
       "      <td>{('[', '''): 10, (''', 'a'): 8, ('a', 'm'): 5,...</td>\n",
       "      <td>{('[', ''', 'a'): 2, (''', 'a', 'm'): 2, ('a',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'[': 10, ''': 212, 'h': 16, 'e': 75, 'a': 44,...</td>\n",
       "      <td>{('[', '''): 10, (''', 'h'): 6, ('h', 'e'): 3,...</td>\n",
       "      <td>{('[', ''', 'h'): 1, (''', 'h', 'e'): 2, ('h',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'[': 10, ''': 190, 'r': 49, 'e': 76, 'v': 15,...</td>\n",
       "      <td>{('[', '''): 10, (''', 'r'): 9, ('r', 'e'): 12...</td>\n",
       "      <td>{('[', ''', 'r'): 3, (''', 'r', 'e'): 6, ('r',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'[': 10, ''': 200, 'p': 18, 'r': 40, 'e': 67,...</td>\n",
       "      <td>{('[', '''): 10, (''', 'p'): 11, ('p', 'r'): 2...</td>\n",
       "      <td>{('[', ''', 'p'): 1, (''', 'p', 'r'): 2, ('p',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'[': 10, ''': 194, 'g': 19, 'r': 35, 'e': 85,...</td>\n",
       "      <td>{('[', '''): 10, (''', 'g'): 5, ('g', 'r'): 2,...</td>\n",
       "      <td>{('[', ''', 'g'): 1, (''', 'g', 'r'): 2, ('g',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>{'[': 10, ''': 188, 'd': 22, 'e': 89, 'm': 20,...</td>\n",
       "      <td>{('[', '''): 10, (''', 'd'): 6, ('d', 'e'): 5,...</td>\n",
       "      <td>{('[', ''', 'd'): 1, (''', 'd', 'e'): 2, ('d',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>{'[': 10, ''': 198, 't': 48, 'e': 76, 'n': 47,...</td>\n",
       "      <td>{('[', '''): 10, (''', 't'): 9, ('t', 'e'): 8,...</td>\n",
       "      <td>{('[', ''', 't'): 1, (''', 't', 'e'): 1, ('t',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>{'[': 10, ''': 182, 's': 36, 'e': 84, 'r': 47,...</td>\n",
       "      <td>{('[', '''): 10, (''', 's'): 16, ('s', 'e'): 1...</td>\n",
       "      <td>{('[', ''', 's'): 2, (''', 's', 'e'): 6, ('s',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>{'[': 10, ''': 204, 'k': 8, 'i': 59, 'd': 31, ...</td>\n",
       "      <td>{('[', '''): 10, (''', 'k'): 3, ('k', 'i'): 5,...</td>\n",
       "      <td>{('[', ''', 'k'): 1, (''', 'k', 'i'): 3, ('k',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>{'[': 8, ''': 172, 'f': 10, 'i': 45, 'r': 48, ...</td>\n",
       "      <td>{('[', '''): 8, (''', 'f'): 7, ('f', 'i'): 1, ...</td>\n",
       "      <td>{('[', ''', 'f'): 2, (''', 'f', 'i'): 1, ('f',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            word_freq  \\\n",
       "1   {'[': 10, ''': 204, 'a': 41, 'm': 17, 'z': 2, ...   \n",
       "2   {'[': 10, ''': 212, 'h': 16, 'e': 75, 'a': 44,...   \n",
       "3   {'[': 10, ''': 190, 'r': 49, 'e': 76, 'v': 15,...   \n",
       "4   {'[': 10, ''': 200, 'p': 18, 'r': 40, 'e': 67,...   \n",
       "5   {'[': 10, ''': 194, 'g': 19, 'r': 35, 'e': 85,...   \n",
       "..                                                ...   \n",
       "58  {'[': 10, ''': 188, 'd': 22, 'e': 89, 'm': 20,...   \n",
       "59  {'[': 10, ''': 198, 't': 48, 'e': 76, 'n': 47,...   \n",
       "60  {'[': 10, ''': 182, 's': 36, 'e': 84, 'r': 47,...   \n",
       "61  {'[': 10, ''': 204, 'k': 8, 'i': 59, 'd': 31, ...   \n",
       "62  {'[': 8, ''': 172, 'f': 10, 'i': 45, 'r': 48, ...   \n",
       "\n",
       "                                          bigram_freq  \\\n",
       "1   {('[', '''): 10, (''', 'a'): 8, ('a', 'm'): 5,...   \n",
       "2   {('[', '''): 10, (''', 'h'): 6, ('h', 'e'): 3,...   \n",
       "3   {('[', '''): 10, (''', 'r'): 9, ('r', 'e'): 12...   \n",
       "4   {('[', '''): 10, (''', 'p'): 11, ('p', 'r'): 2...   \n",
       "5   {('[', '''): 10, (''', 'g'): 5, ('g', 'r'): 2,...   \n",
       "..                                                ...   \n",
       "58  {('[', '''): 10, (''', 'd'): 6, ('d', 'e'): 5,...   \n",
       "59  {('[', '''): 10, (''', 't'): 9, ('t', 'e'): 8,...   \n",
       "60  {('[', '''): 10, (''', 's'): 16, ('s', 'e'): 1...   \n",
       "61  {('[', '''): 10, (''', 'k'): 3, ('k', 'i'): 5,...   \n",
       "62  {('[', '''): 8, (''', 'f'): 7, ('f', 'i'): 1, ...   \n",
       "\n",
       "                                         trigram_freq  \n",
       "1   {('[', ''', 'a'): 2, (''', 'a', 'm'): 2, ('a',...  \n",
       "2   {('[', ''', 'h'): 1, (''', 'h', 'e'): 2, ('h',...  \n",
       "3   {('[', ''', 'r'): 3, (''', 'r', 'e'): 6, ('r',...  \n",
       "4   {('[', ''', 'p'): 1, (''', 'p', 'r'): 2, ('p',...  \n",
       "5   {('[', ''', 'g'): 1, (''', 'g', 'r'): 2, ('g',...  \n",
       "..                                                ...  \n",
       "58  {('[', ''', 'd'): 1, (''', 'd', 'e'): 2, ('d',...  \n",
       "59  {('[', ''', 't'): 1, (''', 't', 'e'): 1, ('t',...  \n",
       "60  {('[', ''', 's'): 2, (''', 's', 'e'): 6, ('s',...  \n",
       "61  {('[', ''', 'k'): 1, (''', 'k', 'i'): 3, ('k',...  \n",
       "62  {('[', ''', 'f'): 2, (''', 'f', 'i'): 1, ('f',...  \n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- Highlighting frequent words ---------- #\n",
    "\n",
    "review_frequent_words = {}\n",
    "\n",
    "def get_frequency(restaurant_id):\n",
    "\n",
    "    # Word Frequency Analysis\n",
    "    all_words = [word for tokens in df[df['restaurant_id'] == restaurant_id]['tokens'] for word in tokens]\n",
    "    word_freq = Counter(all_words)\n",
    "\n",
    "    # N-gram Analysis\n",
    "    bigrams = ngrams(all_words, 2)\n",
    "    bigram_freq = Counter(bigrams)\n",
    "\n",
    "    # Tri-gram Analysis\n",
    "    trigrams = ngrams(all_words, 3)\n",
    "    trigram_freq = Counter(trigrams)\n",
    "\n",
    "    return [word_freq, bigram_freq, trigram_freq]\n",
    "\n",
    "for restaurant_id in df['restaurant_id']:\n",
    "    review_frequent_words[restaurant_id] = get_frequency(restaurant_id)\n",
    "\n",
    "review_frequent_words_df = pd.DataFrame.from_dict(review_frequent_words, orient='index', columns=['word_freq', 'bigram_freq', 'trigram_freq'])\n",
    "review_frequent_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el15613117161316641008217947\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el15613117161316641008217947_data = {\"mdsDat\": {\"x\": [0.39425905455194066, 0.09009589925450281, -0.23664328063543053, -0.24304431291986833, 0.09828469778129069, -0.05284493692450437, -0.0930052796017752, -0.2728443060560079, 0.2223149033644846, 0.09342756118536749], \"y\": [0.149253718724891, 0.30300515201646344, 0.02605960347576295, 0.24535274375807586, -0.33371467355171025, 0.18013771696442438, -0.25200066799470394, -0.15465084833732679, -0.1568784023824518, -0.006564342673424759], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [38.37367098418325, 12.396911413431784, 8.166624833927779, 6.893577819714761, 6.886240894601893, 6.783201540678463, 6.511887628272792, 5.85787973881224, 4.671009403313952, 3.458995743063086]}, \"tinfo\": {\"Term\": [\"service\", \"food\", \"birthday\", \"restaurant\", \"time\", \"experience\", \"atmosphere\", \"course\", \"good\", \"table\", \"service\", \"food\", \"great\", \"alliance\", \"place\", \"nice\", \"wine\", \"wonderful\", \"delicious\", \"well\", \"good\", \"night\", \"restaurant\", \"amazing\", \"meal\", \"little\", \"dish\", \"special\", \"many\", \"day\", \"waiter\", \"fresh\", \"rude\", \"martin\", \"reservation\", \"dinner\", \"french\", \"experience\", \"parking\", \"option\", \"potato\", \"small\", \"location\", \"olive\", \"classic\", \"dine\", \"melon\", \"prosciutto\", \"speak\", \"dining\", \"menu\", \"soup\", \"onion\", \"experience\", \"french\", \"course\", \"thing\", \"life\", \"party\", \"urinary\", \"glass\", \"etouffee\", \"profiterole\", \"third\", \"journey\", \"table\", \"server\", \"birthday\", \"family\", \"warm\", \"super\", \"week\", \"excited\", \"right\", \"copy\", \"celebration\", \"close\", \"fun\", \"time\", \"really\", \"overall\", \"kiss\", \"attentive\", \"fantastic\", \"town\", \"upside\", \"downside\", \"pithivier\", \"city\", \"bread\", \"experience\", \"table\", \"branch\", \"year\", \"last\", \"second\", \"tonight\", \"truly\", \"brasserie\", \"new\", \"son\", \"sick\", \"busy\", \"still\", \"star\", \"time\", \"first\", \"favorite\", \"area\", \"bit\", \"high\", \"mummy\", \"disappointed\", \"kid\", \"extremely\", \"ever\", \"atmosphere\", \"selection\", \"lovely\", \"escargot\", \"surprised\", \"event\", \"hard\", \"interesting\", \"overdue\", \"salmon\", \"anywhere\", \"cave\", \"creek\", \"favorite\", \"back\", \"way\", \"incredible\", \"class\", \"wall\", \"mood\", \"shelf\", \"lighting\", \"pass\", \"enough\", \"moment\", \"highly\", \"server\"], \"Freq\": [173.0, 169.0, 34.0, 131.0, 60.0, 53.0, 30.0, 27.0, 100.0, 32.0, 172.98332675803064, 168.79411340870442, 79.38500081310895, 63.713413007964625, 64.01137865373067, 42.80972989362263, 41.695085238100326, 37.22107358901608, 36.67443735662864, 26.643497735517162, 94.91347676872395, 52.06349254300194, 118.12247928890199, 54.40303033081273, 26.59803410271131, 16.6881974658797, 15.832407882768337, 14.70171652025367, 14.47652593987731, 14.215190029322457, 13.340330060856617, 12.621563570011244, 12.180868254853305, 10.738250026568558, 17.12754401104946, 26.985644161990948, 20.503039171394175, 15.774021349697295, 12.454412611481274, 11.420432362061748, 9.767685768691939, 9.161217322148598, 8.750987178224628, 8.546544347628322, 8.134566188899726, 7.880562878566908, 7.880562878566908, 7.880562878566908, 21.129860645382376, 20.627885471621614, 18.95456997774681, 14.037951113612122, 13.354809700608993, 14.9705671022882, 10.053440780186662, 26.80310824255389, 14.113172300886838, 13.221343818338747, 12.47696451178629, 9.078262151050613, 8.833006947390468, 6.884495593198123, 6.884495593198123, 6.884495593198123, 6.884075143061017, 21.17329197118552, 9.510868197101493, 33.7526758402789, 16.113758378130612, 13.39132174982685, 12.087345375315287, 11.56706946537342, 11.3475454505296, 10.750340371631072, 8.35980688734721, 7.981855821591169, 7.62547726018886, 8.602164203962984, 16.92316663626922, 14.648658093608114, 18.995535942126697, 17.000414552194307, 15.014404292768665, 12.838043262056148, 10.504870623294629, 8.45974144510377, 7.0456194900896865, 7.045351195447759, 6.903959141486136, 6.377649819577166, 22.74758440589101, 11.004532454767944, 7.501974678027698, 21.267948930361037, 18.97911947392199, 11.223199678754806, 10.123695051539366, 9.43632697810078, 9.369880842724985, 8.43798579504152, 7.72604691828745, 7.490691441330206, 5.558899751523678, 8.875236648269425, 11.14042924873583, 15.134035120054998, 11.4666553385017, 10.191543227770365, 16.953492584169737, 14.13390927539523, 13.246982663155427, 11.59223842274008, 8.498383971991759, 7.463705430592288, 5.846958592065638, 5.468598383191893, 27.452682643001033, 4.459015158342307, 9.599888216831284, 14.145516731887136, 8.304562082398968, 7.5509884788063, 6.950859848540039, 6.453569804950134, 6.1314552620236205, 6.023766010801109, 5.704405068790507, 5.704405068790507, 5.704405068790507, 16.38477048706107, 6.355029234794801, 11.356390312585077, 9.598523543150376, 8.718318789107029, 6.977724559398834, 6.533668088943122, 6.2059335840695695, 5.771429832170928, 5.770974185459895, 5.546784106850667, 2.8781541152216206, 3.6514825512111773, 3.994794304523449], \"Total\": [173.0, 169.0, 34.0, 131.0, 60.0, 53.0, 30.0, 27.0, 100.0, 32.0, 173.6280451739908, 169.4390139344442, 80.02972414525661, 64.35809991080254, 64.68226773864185, 43.45467666467171, 42.339752775615494, 37.865723233652744, 37.31916913480532, 27.28819136915734, 100.35631261555343, 54.06897312168821, 131.49340583527186, 58.958719591393866, 27.486952292368326, 17.333205992866084, 16.480982413183373, 15.34674755500077, 15.121787464596462, 14.860206098946534, 13.985554929810293, 13.267176721606601, 12.826219729682956, 11.383440283485191, 22.2796594658082, 73.76317660407064, 71.46806880147228, 53.98792752581204, 13.11575272094649, 12.081538670132328, 10.42896540049282, 9.822307970008676, 9.4120653994297, 9.207957161696008, 8.795621782705298, 8.541661469074276, 8.541661469074276, 8.541661469074276, 24.121768943888387, 33.29020468322175, 32.782989036770196, 23.187885402569098, 23.040263117619688, 53.98792752581204, 71.46806880147228, 27.474115364140342, 14.784312565651899, 13.892432292233531, 13.148153864411977, 9.749301070159564, 9.504028224601488, 7.555520263685204, 7.555520263685204, 7.555520263685204, 7.555199069308632, 32.77850348395657, 19.337115638650836, 34.42522925337534, 16.786271407406083, 14.063871547490143, 12.759843677580387, 12.23960918440296, 12.020100913913932, 11.42312698250675, 9.03233273262058, 8.654352854284898, 8.29798209585519, 10.780928302572201, 60.062164876883536, 50.546246959477514, 19.665034835040323, 17.66988191433738, 15.683817209210568, 13.507554083568456, 11.174452405309447, 9.129157704085593, 7.715163482242422, 7.7148949644156835, 7.57339890946754, 7.0470657859199, 53.98792752581204, 32.77850348395657, 17.4573439630346, 21.93293759897039, 19.64407222185938, 11.88828268363836, 10.788889190335437, 10.101310706885668, 10.03485445275163, 9.102941873248271, 8.391669062403261, 8.155732533688568, 6.223902052285361, 10.806544202116724, 16.813672695843042, 60.062164876883536, 39.869767086994116, 27.184341279731854, 17.618776631123314, 14.799221596210376, 13.91220474496928, 12.257601075904162, 9.163990088873193, 8.129245099401482, 6.512174157216205, 6.133843904105462, 30.872485618099766, 5.124309696896033, 22.06681792512914, 14.828554798664847, 8.987363850117196, 8.233910196412056, 7.633906352623251, 7.1368090968275935, 6.8147686680369475, 6.707015816234534, 6.387178030918561, 6.387178030918561, 6.387178030918561, 27.184341279731854, 10.1424514180617, 12.038592369771875, 10.28084819254, 9.400652399239835, 7.659866592042915, 7.215886924440719, 6.888108126136962, 6.453654481477783, 6.453294771395485, 6.2289480355398394, 3.5602990186699164, 6.920978527232652, 19.337115638650836], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.614, -2.6385, -3.3929, -3.6128, -3.6082, -4.0105, -4.0368, -4.1503, -4.1651, -4.4847, -3.2143, -3.8148, -2.9955, -3.7708, -3.3565, -3.8226, -3.8752, -3.9493, -3.9648, -3.983, -4.0465, -4.1019, -4.1374, -4.2635, -3.7966, -3.342, -3.6167, -3.8789, -3.6978, -3.7845, -3.9408, -4.0049, -4.0507, -4.0744, -4.1238, -4.1555, -4.1555, -4.1555, -3.1692, -3.1933, -3.2779, -3.5781, -3.628, -3.5138, -3.912, -2.7619, -3.4033, -3.4686, -3.5266, -3.8446, -3.8719, -4.1212, -4.1212, -4.1212, -4.1212, -2.9977, -3.798, -2.5303, -3.2697, -3.4548, -3.5572, -3.6012, -3.6204, -3.6744, -3.9259, -3.9722, -4.0179, -3.8974, -3.2207, -3.365, -3.0901, -3.2011, -3.3253, -3.4819, -3.6825, -3.899, -4.0819, -4.0819, -4.1022, -4.1815, -2.9098, -3.636, -4.0191, -2.9363, -3.0501, -3.5755, -3.6786, -3.7489, -3.756, -3.8607, -3.9489, -3.9798, -4.2781, -3.8102, -3.5829, -3.2765, -3.554, -3.6719, -3.0572, -3.2391, -3.3039, -3.4373, -3.7478, -3.8776, -4.1217, -4.1886, -2.5752, -4.3927, -3.6259, -3.0118, -3.5444, -3.6395, -3.7224, -3.7966, -3.8478, -3.8655, -3.92, -3.92, -3.92, -2.8649, -3.812, -2.931, -3.0992, -3.1954, -3.4181, -3.4839, -3.5353, -3.6079, -3.608, -3.6476, -4.3037, -4.0657, -3.9758], \"loglift\": [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9541, 0.954, 0.9497, 0.9477, 0.9474, 0.9428, 0.9425, 0.9406, 0.9404, 0.9339, 0.902, 0.92, 0.8506, 0.8774, 2.0548, 2.0498, 2.0476, 2.0448, 2.0441, 2.0433, 2.0405, 2.0378, 2.0361, 2.0294, 1.8247, 1.0822, 0.839, 0.8573, 2.4534, 2.4488, 2.4396, 2.4354, 2.4323, 2.4306, 2.427, 2.4246, 2.4246, 2.4246, 2.3727, 2.0265, 1.9572, 2.0032, 1.9597, 1.2224, 0.5438, 2.6499, 2.6281, 2.6251, 2.6222, 2.6033, 2.6014, 2.5816, 2.5816, 2.5816, 2.5816, 2.2375, 1.965, 2.6559, 2.6348, 2.6266, 2.6215, 2.6191, 2.6181, 2.6149, 2.5983, 2.5948, 2.5911, 2.4499, 1.4089, 1.4371, 2.6561, 2.6521, 2.6471, 2.6399, 2.6289, 2.6146, 2.5999, 2.5999, 2.5982, 2.5909, 1.8264, 1.5993, 1.8461, 2.7008, 2.6971, 2.674, 2.6679, 2.6634, 2.663, 2.6557, 2.6489, 2.6465, 2.6185, 2.5347, 2.3199, 1.3531, 1.4854, 1.7505, 2.7989, 2.7914, 2.7884, 2.7816, 2.762, 2.752, 2.7296, 2.7226, 2.72, 2.6983, 2.0051, 3.0166, 2.9848, 2.9772, 2.9701, 2.9632, 2.9581, 2.9564, 2.9507, 2.9507, 2.9507, 2.5575, 2.5963, 3.3059, 3.2955, 3.2888, 3.2709, 3.2649, 3.2599, 3.2525, 3.2524, 3.2482, 3.1515, 2.7248, 1.7872]}, \"token.table\": {\"Topic\": [1, 1, 6, 9, 8, 3, 8, 6, 4, 9, 5, 8, 2, 6, 7, 6, 7, 9, 5, 6, 10, 3, 5, 5, 4, 9, 2, 1, 3, 2, 3, 1, 2, 3, 4, 6, 8, 2, 6, 10, 9, 4, 9, 8, 5, 2, 3, 6, 8, 5, 6, 7, 9, 1, 7, 1, 1, 2, 3, 2, 5, 9, 4, 1, 3, 1, 9, 8, 8, 10, 10, 9, 4, 8, 6, 7, 4, 10, 2, 3, 2, 8, 2, 2, 2, 3, 2, 3, 9, 10, 10, 8, 7, 1, 1, 6, 3, 2, 3, 3, 6, 9, 3, 4, 10, 6, 1, 3, 4, 3, 1, 2, 5, 2, 4, 1, 3, 7, 5, 2, 9, 7, 8, 4, 6, 10, 1, 10, 7, 3, 7, 2, 3, 3, 8, 2, 7, 8, 3, 7, 5, 9, 4, 6, 4, 4, 1, 5, 7, 7, 6, 7, 6, 4, 2, 10, 5, 10, 5, 1, 1, 1, 7], \"Freq\": [0.9944358221995546, 0.9158950597000807, 0.06784407849630227, 0.9393819885645368, 0.9648797050965359, 0.09717390549989195, 0.8745651494990275, 0.956399822818071, 0.29578647965299526, 0.5915729593059905, 0.9876477437449847, 0.9459957004485268, 0.5155423424695778, 0.45825985997295804, 0.8968739947725037, 0.8514181905308807, 0.9640254537419743, 0.9393819885645368, 0.9243903194955914, 0.9242877714059494, 0.9573803623169566, 0.9095434294060122, 0.9640898121479401, 0.8857069637290625, 0.9827431981755756, 0.9393819885645368, 0.9421134476050426, 0.9914475819744966, 0.9365859357649092, 0.3604663928680497, 0.630816187519087, 0.44737769601667193, 0.36603629674091337, 0.09489829915505162, 0.013556899879293089, 0.06778449939646544, 0.8729821750586029, 0.9708159136922185, 0.9073041700427378, 0.9632445102714687, 0.9441243728795844, 0.9264749157837281, 0.9715918450854634, 0.815149533990168, 0.915133747942739, 0.29636255239377873, 0.27783989286916755, 0.4260211690660569, 0.9213512807164931, 0.9531598537684085, 0.9624244270703398, 0.3678588308283128, 0.5885741293253005, 0.7022865204831823, 0.2758982759041073, 0.9974090150535575, 0.5596905117320866, 0.2938375186593455, 0.13992262793302165, 0.9798618253745363, 0.8348075181849328, 0.18551278181887396, 0.9469668847050776, 0.9466270484042943, 0.04982247623180497, 0.987133228856473, 0.9169617331753852, 0.9344313312166328, 0.4334647171921725, 0.57795295625623, 0.9726823908611169, 0.8407118529577987, 0.9265143030361691, 0.8610885653472765, 0.9620890554003172, 0.9672128968685691, 0.935761263869363, 0.9297057995931162, 0.9807764361074793, 0.956219450041787, 0.5438029189670659, 0.4531690991392216, 0.9258164772370449, 0.9663159577477226, 0.9822842384565302, 0.9365859357649092, 0.2745326239137432, 0.5795688727067912, 0.12201449951721921, 0.8426258536904473, 0.9700817201403898, 0.9789843808499731, 0.8788367663326955, 0.9895367610676216, 0.9617345586158672, 0.01849489535799745, 0.9774154942248119, 0.39062053909954647, 0.5642296675882338, 0.910480055590429, 0.9661818633621068, 0.880440744546704, 0.9149303326552826, 0.9126756595448979, 0.9297576218887855, 0.9073357488711022, 0.9894520127000084, 0.9588678853539443, 0.9264749157837281, 0.9365859357649092, 0.6330836001662818, 0.07913545002078523, 0.2967579375779446, 0.7630278203349244, 0.22441994715733074, 0.8973834029960734, 0.03041977637274825, 0.06844449683868356, 0.9629587429821342, 0.9355835353599249, 0.894585634564454, 0.9252808242135016, 0.7805929455089209, 0.5171402078194174, 0.2585701039097087, 0.20685608312776696, 0.9963828126190014, 0.8710664655847908, 0.8582920014953129, 0.9162815936417895, 0.9533264408438084, 0.38813371050224554, 0.6037635496701598, 0.870582918228336, 0.08291265887888914, 0.9774057953479673, 0.6542294594993279, 0.297377027045149, 0.09253652058390005, 0.8328286852551005, 0.9404503929060302, 0.8901386583893206, 0.6406637816847998, 0.3355857904063237, 0.9469496764107872, 0.9264749157837281, 0.44953424598239283, 0.28304008080372883, 0.24974124776799603, 0.9268794797668221, 0.984388281503033, 0.8909734846454186, 0.8763130465387559, 0.9231430986931968, 0.929530509532405, 0.913854035953004, 0.9243542900759782, 0.9137280889766055, 0.9804234611748637, 0.9894389714122619, 0.9919755607120322, 0.9771370210385063, 0.9574640836522424], \"Term\": [\"alliance\", \"amazing\", \"amazing\", \"anywhere\", \"area\", \"atmosphere\", \"atmosphere\", \"attentive\", \"back\", \"back\", \"birthday\", \"bit\", \"branch\", \"branch\", \"brasserie\", \"bread\", \"busy\", \"cave\", \"celebration\", \"city\", \"class\", \"classic\", \"close\", \"copy\", \"course\", \"creek\", \"day\", \"delicious\", \"dine\", \"dining\", \"dining\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"disappointed\", \"dish\", \"downside\", \"enough\", \"escargot\", \"etouffee\", \"event\", \"ever\", \"excited\", \"experience\", \"experience\", \"experience\", \"extremely\", \"family\", \"fantastic\", \"favorite\", \"favorite\", \"first\", \"first\", \"food\", \"french\", \"french\", \"french\", \"fresh\", \"fun\", \"fun\", \"glass\", \"good\", \"good\", \"great\", \"hard\", \"high\", \"highly\", \"highly\", \"incredible\", \"interesting\", \"journey\", \"kid\", \"kiss\", \"last\", \"life\", \"lighting\", \"little\", \"location\", \"lovely\", \"lovely\", \"many\", \"martin\", \"meal\", \"melon\", \"menu\", \"menu\", \"menu\", \"moment\", \"mood\", \"mummy\", \"new\", \"nice\", \"night\", \"night\", \"olive\", \"onion\", \"onion\", \"option\", \"overall\", \"overdue\", \"parking\", \"party\", \"pass\", \"pithivier\", \"place\", \"potato\", \"profiterole\", \"prosciutto\", \"really\", \"really\", \"really\", \"reservation\", \"reservation\", \"restaurant\", \"restaurant\", \"restaurant\", \"right\", \"rude\", \"salmon\", \"second\", \"selection\", \"server\", \"server\", \"server\", \"service\", \"shelf\", \"sick\", \"small\", \"son\", \"soup\", \"soup\", \"speak\", \"speak\", \"special\", \"star\", \"star\", \"still\", \"still\", \"super\", \"surprised\", \"table\", \"table\", \"thing\", \"third\", \"time\", \"time\", \"time\", \"tonight\", \"town\", \"truly\", \"upside\", \"urinary\", \"waiter\", \"wall\", \"warm\", \"way\", \"week\", \"well\", \"wine\", \"wonderful\", \"year\"]}, \"R\": 10, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 10, 4, 5, 7, 1, 8, 9, 2, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el15613117161316641008217947\", ldavis_el15613117161316641008217947_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el15613117161316641008217947\", ldavis_el15613117161316641008217947_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el15613117161316641008217947\", ldavis_el15613117161316641008217947_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- Topic Modelling ---------- #\n",
    "\n",
    "# We convert the tokens into tuples where we'll have the word index (its placement on the map) and its frequency\n",
    "id2word = corpora.Dictionary(df['tokens'])\n",
    "corpus = [id2word.doc2bow(text) for text in df['tokens']]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=10,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "pyLDAvis.enable_notebook(local=True)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds', R=10)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_topic_distribution\u001b[39m(lda_model, bow):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lda_model\u001b[38;5;241m.\u001b[39mget_document_topics(bow, minimum_probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_distribution\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [get_topic_distribution(lda_model, corpus[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_top_topics\u001b[39m(topic_distribution, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Sort the topics by probability and select the top ones\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(topic_distribution, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:num_topics]\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_topic_distribution\u001b[39m(lda_model, bow):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lda_model\u001b[38;5;241m.\u001b[39mget_document_topics(bow, minimum_probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_distribution\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [get_topic_distribution(\u001b[43mlda_model\u001b[49m, corpus[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_top_topics\u001b[39m(topic_distribution, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Sort the topics by probability and select the top ones\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(topic_distribution, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:num_topics]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "def get_topic_distribution(lda_model, bow):\n",
    "    return lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "\n",
    "df['topic_distribution'] = [get_topic_distribution(lda_model, corpus[i]) for i in range(len(df))]\n",
    "\n",
    "def get_top_topics(topic_distribution, num_topics=5):\n",
    "    # Sort the topics by probability and select the top ones\n",
    "    return sorted(topic_distribution, key=lambda x: x[1], reverse=True)[:num_topics]\n",
    "\n",
    "df['top_topics'] = df['topic_distribution'].apply(lambda x: get_top_topics(x, 11 - 1))\n",
    "\n",
    "def label_topics(topic_list, lda_model):\n",
    "    labels = []\n",
    "    for topic_id, _ in topic_list:\n",
    "        # Get the top words in the topic\n",
    "        words = lda_model.show_topic(topic_id, 5)\n",
    "        # Create a label (e.g., by joining the top words)\n",
    "        label = [word for word, prob in words]\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def topicise(labels, label_dict):\n",
    "    topics = []\n",
    "\n",
    "    for topic_list in labels:\n",
    "        for key, value in label_dict.items():\n",
    "            if set(topic_list) == set(value):\n",
    "                topics.append(key)\n",
    "\n",
    "    return topics\n",
    "\n",
    "label_dict = {\n",
    "    'Quality of Food & Service' : ['service', 'food', 'restaurant', 'good', 'great'],\n",
    "    'French Dining Experience' : ['dinner', 'meal', 'french', 'reservation', 'little'],\n",
    "    'Atmosphere' : ['speak', 'dining', 'menu', 'experience', 'soup'],\n",
    "    'Price' : ['course', 'table', 'thing', 'life', 'party'],\n",
    "    'Special Occasions' : ['birthday', 'time', 'family', 'really', 'warm'],\n",
    "    'Ambience' : ['experience', 'overall', 'kiss', 'attentive', 'fantastic'],\n",
    "    'Dining Experience' : ['experience', 'overall', 'kiss', 'attentive', 'fantastic'],\n",
    "    'Staff' : ['year', 'last', 'time', 'first', 'second'],\n",
    "    'Menu' : ['atmosphere', 'area', 'bit', 'high', 'mummy'],\n",
    "    'Drinks' : ['way', 'incredible', 'class', 'wall', 'mood'] \n",
    "}\n",
    "\n",
    "df['top_topic_labels'] = df['top_topics'].apply(lambda x: label_topics(x, lda_model))\n",
    "df['topics'] = df['top_topic_labels'].apply(lambda x: topicise(x, label_dict))\n",
    "df.drop(columns=['topic_distribution', 'top_topics'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases alogrithm\n",
    "\n",
    "min_count = 3\n",
    "threshold = 5\n",
    "\n",
    "phrases = Phrases(df['tokens'], min_count=min_count, threshold=threshold)\n",
    "phraser = Phraser(phrases)\n",
    "\n",
    "df['bigrams'] = phraser[ df['tokens']]\n",
    "df['trigrams'] = phraser[df['bigrams']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (_worker_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/gensim/models/word2vec.py\", line 1166, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/gensim/models/word2vec.py\", line 957, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 638, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "  File \"/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/generic.py\", line 1519, in __nonzero__\n",
      "    raise ValueError(\n",
      "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    }
   ],
   "source": [
    "vector_size = 100\n",
    "window = 5\n",
    "min_count = 1\n",
    "workers = 4\n",
    "\n",
    "# Training the model\n",
    "word2vec_model = Word2Vec(sentences=[df['bigrams']], vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
    "\n",
    "# Save the model\n",
    "word2vec_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.782258064516129\n",
      "Logistic Regression Precision: 0.782258064516129\n",
      "Logistic Regression Recall: 0.782258064516129\n"
     ]
    }
   ],
   "source": [
    "# file_name = \"word2vec.model\"\n",
    "# model = gensim.models.keyedvectors.KeyedVectors.load(file_name)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "def vectorize_model(sent, model):\n",
    "    vector_size = model.vector_size\n",
    "    model_res = np.zeros(vector_size)\n",
    "    ctr = 0\n",
    "    for word in sent:\n",
    "        if word in model.wv.key_to_index:\n",
    "            ctr += 1\n",
    "            model_res += model.wv[word]\n",
    "    if ctr > 0:\n",
    "        model_res = model_res / ctr\n",
    "    return model_res\n",
    "\n",
    "df['vectors'] = df['tokens'].apply(lambda x: vectorize_model(x, model))\n",
    "\n",
    "X = df['vectors'].to_list()\n",
    "y = df['sentiment'].to_list()\n",
    "\n",
    "test_size = 0.2\n",
    "stratify_value = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,stratify=stratify_value, random_state=42)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted, average='micro'))  # Change average to 'micro', 'macro', 'weighted', or None\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted, average='micro'))  # Change average to 'micro', 'macro', 'weighted', or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", ' ', ',', 'e', 'a', 'r', 'i', 't', 'n', 'o', 'l', 's', 'c', 'd', 'u', 'p', 'f', 'g', 'h', 'm', 'y', '[', ']', 'v', 'b', 'w', 'k', 'x', 'z', 'q', 'j', 'û', 'é']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tsne_plot(model):\n",
    "    vocab = model.wv.index_to_key\n",
    "\n",
    "    print(vocab)\n",
    "\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in vocab:\n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "        #print(tokens)\n",
    "        #print(labels)\n",
    "    tokens = np.array(tokens)\n",
    "    tsne_model = TSNE(perplexity=20, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "tsne_plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 14:44:11.424838: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-01-20 14:44:11.424875: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-20 14:44:11.424886: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-20 14:44:11.427800: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-20 14:44:11.430655: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-01-20 14:44:11.463036: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projections/model.ckpt-1457'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"word2vec.model\"\n",
    "model = gensim.models.keyedvectors.KeyedVectors.load(file_name)\n",
    "\n",
    "max_size = len(model.wv.index_to_key)-1\n",
    "\n",
    "w2v = np.zeros((max_size,model.vector_size))\n",
    "\n",
    "if not os.path.exists('projections'):\n",
    "    os.makedirs('projections')\n",
    "    \n",
    "with open(\"projections/metadata.tsv\", 'w+') as file_metadata:\n",
    "    \n",
    "    for i, word in enumerate(model.wv.index_to_key[:max_size]):\n",
    "        \n",
    "        #store the embeddings of the word\n",
    "        w2v[i] = model.wv[word]\n",
    "        \n",
    "        #write the word to a file \n",
    "        file_metadata.write(word + '\\n')\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.Variable(w2v, trainable=False, name='embedding')\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "writer = tf.compat.v1.summary.FileWriter('projections', sess.graph)\n",
    "config = projector.ProjectorConfig()\n",
    "embed= config.embeddings.add()\n",
    "\n",
    "embed.tensor_name = 'embedding'\n",
    "embed.metadata_path = 'metadata.tsv'\n",
    "\n",
    "projector.visualize_embeddings(writer, config)\n",
    "saver.save(sess, 'projections/model.ckpt', global_step=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wine',\n",
       " 'food',\n",
       " 'dinner',\n",
       " 'french',\n",
       " 'truly',\n",
       " 'great',\n",
       " 'service',\n",
       " 'place',\n",
       " 'old',\n",
       " 'good']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def semantic_search(query_word, model, topn=10):\n",
    "    query_vector = model.wv[query_word]\n",
    "    all_words = model.wv.index_to_key\n",
    "\n",
    "    # Calculate cosine distance between query and all other words\n",
    "    distances = {word: cosine(query_vector, model.wv[word]) for word in all_words}\n",
    "    \n",
    "    # Sort words by distance (lower is more similar)\n",
    "    sorted_words = sorted(distances, key=distances.get)\n",
    "\n",
    "    # Return the topn closest words\n",
    "    return sorted_words[:topn]\n",
    "\n",
    "# Example usage\n",
    "search_results = semantic_search('wine', word2vec_model)\n",
    "\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've decided to go with this: BERT for Text Classification: Given its context-aware nature and superior performance in understanding nuances, BERT is generally the better choice for text classification.\n",
    "Word2Vec for Semantic Search: For semantic search tasks, Word2Vec's efficiency and effectiveness in finding similar words make it a strong choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokeniser = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "def sentiment_score(review):\n",
    "    tokens = tokeniser.encode(review, return_tensors=\"pt\")\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "# Example usage\n",
    "example_sentence = 'It was great, I will come back again.'\n",
    "sentiment_probabilities = sentiment_score(example_sentence)\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['sentiment'] = df['text'].apply(lambda x: sentiment_score(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>top_topic_labels</th>\n",
       "      <th>topics</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robyn gave amazing service! So attentive and f...</td>\n",
       "      <td>5</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[amazing, service, attentive, friendly, stuff,...</td>\n",
       "      <td>robin gave amazing service! so attentive and f...</td>\n",
       "      <td>[['experience', 'overall', 'kiss', 'attentive'...</td>\n",
       "      <td>['Ambience', 'Dining Experience', 'Quality of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Headed downtown on a Thursday evening for a Ki...</td>\n",
       "      <td>5</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[downtown, evening, king, game, time, dinner, ...</td>\n",
       "      <td>headed downtown on a thursday evening for a ki...</td>\n",
       "      <td>[['course', 'table', 'thing', 'life', 'party']...</td>\n",
       "      <td>['Price', 'Quality of Food &amp; Service', 'Staff'...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Been here a few times, in just recent weeks. T...</td>\n",
       "      <td>4</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[time, recent, week, visit, rooftop, bar, time...</td>\n",
       "      <td>been here a few times, in just recent weeks. t...</td>\n",
       "      <td>[['birthday', 'time', 'family', 'really', 'war...</td>\n",
       "      <td>['Special Occasions', 'Quality of Food &amp; Servi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Service is fast. Staff is friendly. The food i...</td>\n",
       "      <td>5</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[service, fast, staff, friendly, food, whole, ...</td>\n",
       "      <td>service is fast. staff is friendly. the food i...</td>\n",
       "      <td>[['service', 'food', 'restaurant', 'good', 'gr...</td>\n",
       "      <td>['Quality of Food &amp; Service', 'Special Occasio...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walked by and asked to see a menu. Very helpfu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[menu, helpful, staff, french, concept, try, a...</td>\n",
       "      <td>walked by and asked to see a menu. very helpfu...</td>\n",
       "      <td>[['service', 'food', 'restaurant', 'good', 'gr...</td>\n",
       "      <td>['Quality of Food &amp; Service', 'Atmosphere', 'F...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>The Steak Tartare is absolutely yummy! Just as...</td>\n",
       "      <td>5</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>[tartar, absolutely, mummy, waiter, drop, bran...</td>\n",
       "      <td>the speak tartar is absolutely mummy! just ask...</td>\n",
       "      <td>[['service', 'food', 'restaurant', 'good', 'gr...</td>\n",
       "      <td>['Quality of Food &amp; Service', 'French Dining E...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>The culinary journey begins right at your tabl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Miami</td>\n",
       "      <td>[urinary, journey, right, table, fresh, potato...</td>\n",
       "      <td>the urinary journey begins right at your table...</td>\n",
       "      <td>[['course', 'table', 'thing', 'life', 'party']...</td>\n",
       "      <td>['Price', 'Quality of Food &amp; Service', 'Atmosp...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Very nice ambiance. We went there at night, an...</td>\n",
       "      <td>4</td>\n",
       "      <td>New York City</td>\n",
       "      <td>[nice, alliance, night, inside, warm, lighting...</td>\n",
       "      <td>very nice alliance. we went there at night, an...</td>\n",
       "      <td>[['service', 'food', 'restaurant', 'good', 'gr...</td>\n",
       "      <td>['Quality of Food &amp; Service', 'Drinks', 'Speci...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>M. whatever ... this is a hard pass.... I know...</td>\n",
       "      <td>1</td>\n",
       "      <td>New York City</td>\n",
       "      <td>[hard, pass, short, rude, thing, bartender, mo...</td>\n",
       "      <td>m. whatever ... this is a hard pass.... i know...</td>\n",
       "      <td>[['service', 'food', 'restaurant', 'good', 'gr...</td>\n",
       "      <td>['Quality of Food &amp; Service', 'Drinks', 'Frenc...</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Food and service are over the moo wonderful, s...</td>\n",
       "      <td>5</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>[food, service, wonderful, service, fantastic,...</td>\n",
       "      <td>food and service are over the too wonderful, s...</td>\n",
       "      <td>[['service', 'food', 'restaurant', 'good', 'gr...</td>\n",
       "      <td>['Quality of Food &amp; Service', 'Ambience', 'Din...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  rating       location  \\\n",
       "0    Robyn gave amazing service! So attentive and f...       5    Los Angeles   \n",
       "1    Headed downtown on a Thursday evening for a Ki...       5    Los Angeles   \n",
       "2    Been here a few times, in just recent weeks. T...       4    Los Angeles   \n",
       "3    Service is fast. Staff is friendly. The food i...       5    Los Angeles   \n",
       "4    Walked by and asked to see a menu. Very helpfu...       3    Los Angeles   \n",
       "..                                                 ...     ...            ...   \n",
       "613  The Steak Tartare is absolutely yummy! Just as...       5        Phoenix   \n",
       "614  The culinary journey begins right at your tabl...       5          Miami   \n",
       "615  Very nice ambiance. We went there at night, an...       4  New York City   \n",
       "616  M. whatever ... this is a hard pass.... I know...       1  New York City   \n",
       "617  Food and service are over the moo wonderful, s...       5    New Orleans   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [amazing, service, attentive, friendly, stuff,...   \n",
       "1    [downtown, evening, king, game, time, dinner, ...   \n",
       "2    [time, recent, week, visit, rooftop, bar, time...   \n",
       "3    [service, fast, staff, friendly, food, whole, ...   \n",
       "4    [menu, helpful, staff, french, concept, try, a...   \n",
       "..                                                 ...   \n",
       "613  [tartar, absolutely, mummy, waiter, drop, bran...   \n",
       "614  [urinary, journey, right, table, fresh, potato...   \n",
       "615  [nice, alliance, night, inside, warm, lighting...   \n",
       "616  [hard, pass, short, rude, thing, bartender, mo...   \n",
       "617  [food, service, wonderful, service, fantastic,...   \n",
       "\n",
       "                                          cleaned_text  \\\n",
       "0    robin gave amazing service! so attentive and f...   \n",
       "1    headed downtown on a thursday evening for a ki...   \n",
       "2    been here a few times, in just recent weeks. t...   \n",
       "3    service is fast. staff is friendly. the food i...   \n",
       "4    walked by and asked to see a menu. very helpfu...   \n",
       "..                                                 ...   \n",
       "613  the speak tartar is absolutely mummy! just ask...   \n",
       "614  the urinary journey begins right at your table...   \n",
       "615  very nice alliance. we went there at night, an...   \n",
       "616  m. whatever ... this is a hard pass.... i know...   \n",
       "617  food and service are over the too wonderful, s...   \n",
       "\n",
       "                                      top_topic_labels  \\\n",
       "0    [['experience', 'overall', 'kiss', 'attentive'...   \n",
       "1    [['course', 'table', 'thing', 'life', 'party']...   \n",
       "2    [['birthday', 'time', 'family', 'really', 'war...   \n",
       "3    [['service', 'food', 'restaurant', 'good', 'gr...   \n",
       "4    [['service', 'food', 'restaurant', 'good', 'gr...   \n",
       "..                                                 ...   \n",
       "613  [['service', 'food', 'restaurant', 'good', 'gr...   \n",
       "614  [['course', 'table', 'thing', 'life', 'party']...   \n",
       "615  [['service', 'food', 'restaurant', 'good', 'gr...   \n",
       "616  [['service', 'food', 'restaurant', 'good', 'gr...   \n",
       "617  [['service', 'food', 'restaurant', 'good', 'gr...   \n",
       "\n",
       "                                                topics  restaurant_id  \\\n",
       "0    ['Ambience', 'Dining Experience', 'Quality of ...              1   \n",
       "1    ['Price', 'Quality of Food & Service', 'Staff'...              1   \n",
       "2    ['Special Occasions', 'Quality of Food & Servi...              1   \n",
       "3    ['Quality of Food & Service', 'Special Occasio...              1   \n",
       "4    ['Quality of Food & Service', 'Atmosphere', 'F...              1   \n",
       "..                                                 ...            ...   \n",
       "613  ['Quality of Food & Service', 'French Dining E...             62   \n",
       "614  ['Price', 'Quality of Food & Service', 'Atmosp...             62   \n",
       "615  ['Quality of Food & Service', 'Drinks', 'Speci...             62   \n",
       "616  ['Quality of Food & Service', 'Drinks', 'Frenc...             62   \n",
       "617  ['Quality of Food & Service', 'Ambience', 'Din...             62   \n",
       "\n",
       "     sentiment  \n",
       "0            3  \n",
       "1            2  \n",
       "2            2  \n",
       "3            3  \n",
       "4            3  \n",
       "..         ...  \n",
       "613          3  \n",
       "614          3  \n",
       "615          3  \n",
       "616          1  \n",
       "617          3  \n",
       "\n",
       "[618 rows x 9 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_new_reviews(df):\n",
    "    # Record original data types\n",
    "    original_dtypes = df.dtypes\n",
    "\n",
    "    sentiment_1_rows = df[df['sentiment'] == df['sentiment'].value_counts().index[1]]\n",
    "    sentiment_2_rows = df[df['sentiment'] == df['sentiment'].value_counts().index[2]]\n",
    "    \n",
    "    for i in range(df['sentiment'].value_counts().iloc[0] - df['sentiment'].value_counts().iloc[1] - 1):\n",
    "        random_row = random.choice(sentiment_1_rows.index)\n",
    "        target_row = df.loc[random_row].copy()  # Make a copy of the selected row\n",
    "        \n",
    "        new_review = generate_new_reviews(target_row['cleaned_text'])\n",
    "        target_row['cleaned_text'] = preprocessing(new_review[0])\n",
    "\n",
    "        # Convert target_row to DataFrame and transpose\n",
    "        new_row_df = pd.DataFrame(target_row).transpose()\n",
    "\n",
    "        # Set data types explicitly\n",
    "        for col in new_row_df.columns:\n",
    "            new_row_df[col] = new_row_df[col].astype(original_dtypes[col])\n",
    "\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "    for i in range(df['sentiment'].value_counts().iloc[0] - df['sentiment'].value_counts().iloc[2] - 1):\n",
    "        random_row = random.choice(sentiment_2_rows.index)\n",
    "        target_row = df.loc[random_row].copy()  # Make a copy of the selected row\n",
    "        \n",
    "        new_review = generate_new_reviews(target_row['cleaned_text'])\n",
    "        target_row['cleaned_text'] = preprocessing(new_review[0])\n",
    "\n",
    "        # Convert target_row to DataFrame and transpose\n",
    "        new_row_df = pd.DataFrame(target_row).transpose()\n",
    "\n",
    "        # Set data types explicitly\n",
    "        for col in new_row_df.columns:\n",
    "            new_row_df[col] = new_row_df[col].astype(original_dtypes[col])\n",
    "\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "generated_df = push_new_reviews(df)\n",
    "generated_df = generated_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we add a tensorboard?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.97      0.96       102\n",
      "           2       0.91      0.96      0.93       102\n",
      "           3       0.94      0.85      0.89        85\n",
      "\n",
      "    accuracy                           0.93       289\n",
      "   macro avg       0.93      0.93      0.93       289\n",
      "weighted avg       0.93      0.93      0.93       289\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(generated_df['cleaned_text'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, generated_df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "def classify_review(review_text):\n",
    "    # Preprocess the review_text similar to your training data preprocessing\n",
    "    preprocessed_text = preprocessing(review_text)  # Implement this function based on your preprocessing steps\n",
    "    \n",
    "    # Transform the review text to TF-IDF features\n",
    "    tfidf_features = tfidf_vectorizer.transform([preprocessed_text])\n",
    "    \n",
    "    # Predict the label\n",
    "    predicted_label = classifier.predict(tfidf_features)\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "classify_review(\"This is a great restaurant! I loved the food and the service was amazing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# Fit the pipeline with your data\n",
    "pipeline.fit(generated_df['cleaned_text'], generated_df['sentiment'])\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(pipeline, 'review_classification_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 15:08:02.257800: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-20 15:08:02.257862: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/client/session.py:1770: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projections/tfidf.ckpt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "# Assuming X_tfidf is your TF-IDF matrix\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)  # Reduce to 50 dimensions\n",
    "X_reduced = svd.fit_transform(X_tfidf)\n",
    "\n",
    "# Create a projection directory\n",
    "if not os.path.exists('projections'):\n",
    "    os.makedirs('projections')\n",
    "\n",
    "# Save the reduced embeddings and feature names\n",
    "with open(\"projections/metadata.tsv\", 'w+') as file_metadata:\n",
    "    # Use get_feature_names_out() for scikit-learn 0.24 and newer\n",
    "    for feature_name in tfidf_vectorizer.get_feature_names_out():\n",
    "        file_metadata.write(feature_name + '\\n')\n",
    "\n",
    "# TF-IDF embeddings after dimensionality reduction\n",
    "tfidf_embeddings = np.array(X_reduced)\n",
    "\n",
    "# Disable eager execution (needed for TensorBoard in TF1.x)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Start an interactive session\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "# Create a TensorFlow variable for the embeddings\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding_var = tf.Variable(tfidf_embeddings, trainable=False, name='tfidf_embedding')\n",
    "\n",
    "# Initialize the variable\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "# Save the embeddings in a checkpoint\n",
    "saver = tf.compat.v1.train.Saver([embedding_var])  # Add embedding_var to the saver\n",
    "writer = tf.compat.v1.summary.FileWriter('projections', sess.graph)\n",
    "\n",
    "# Setup the projector configuration\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "\n",
    "# Visualize embeddings\n",
    "projector.visualize_embeddings(writer, config)\n",
    "saver.save(sess, 'projections/tfidf.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 16:33:50.937 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "def resize_image(image_path, width, height):\n",
    "    image = Image.open(image_path)\n",
    "    resized_image = image.resize((width, height))\n",
    "    return resized_image\n",
    "\n",
    "st.set_page_config(page_title=\"Gastonomy\", page_icon=\"🍽️\", layout=\"wide\")\n",
    "    \n",
    "st.sidebar.markdown(\"Select a city and a restaurant to generate a review.\")\n",
    "city = st.sidebar.selectbox(\"City\", sorted(df['location'].unique()))\n",
    "\n",
    "# Dictionary mapping city names to image filenames\n",
    "city_images = {\n",
    "    'New Orleans': 'resources/new-orleans.jpg',\n",
    "    'New York City': 'resources/new-york.jpg',\n",
    "    'Chicago': 'resources/chicago.jpg',\n",
    "    'Los Angeles': 'resources/los-angeles.jpg',\n",
    "    'San Francisco': 'resources/san-francisco.jpg',\n",
    "    'Philadelphia': 'resources/philadelphia.jpg',\n",
    "    'Las Vegas': 'resources/las-vegas.jpg',\n",
    "    'Houston': 'resources/houston.jpg',\n",
    "    'Phoenix': 'resources/phoenix.jpg',\n",
    "    'Miami': 'resources/miami.jpg'\n",
    "}\n",
    "\n",
    "# Display image based on selected city\n",
    "if city in city_images:\n",
    "    image_filename = city_images[city]\n",
    "    resized_image = resize_image(image_filename, 1920, 1080)\n",
    "    st.image(resized_image, caption=city)\n",
    "else:\n",
    "    st.write(\"Image not found for selected city.\")\n",
    "\n",
    "st.title(\"Restaurant Review Analysis\")\n",
    "\n",
    "st.header(\"Quel sont les aspects les plus importants pour vous dans un restaurant?\")\n",
    "topics = st.multiselect(\"Choisissez vos aspects\", sorted(label_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire: Faire choisir a l'utilisateur un ou des topics qu'il aimerait aborder. (S'il est interesse par le food quality par exemple on lui recommandera un restaurant avec une tres bonne food quality - peux-t-on recuperer les restaurants qui correspondent aux avis?).\n",
    "\n",
    "Montrer aussi les topics principaux les plus importants pour les resturants francais de chaque ville\n",
    "\n",
    "Later on, maybe use these topics to enhance the importance of them in summarised reviews.\n",
    "\n",
    "What I suggest is this: Topics principaux par villes. On demande a l'utilisateur de choisir ce qu'il prefere a travers un chatbot et ensuite on trouve les restaurants avec les meilleurs topics et de ce resturant on montre aussi ses meilleurs atouts avec les topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
