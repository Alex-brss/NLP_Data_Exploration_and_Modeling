{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow_hub/__init__.py:61: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import parse_version\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:121: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"best_of\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:140: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"repetition_penalty\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:146: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"seed\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:152: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"temperature\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:158: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"top_k\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:164: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"top_p\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:170: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"truncate\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:176: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"typical_p\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:204: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"inputs\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:210: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"stream\")\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gensim.downloader as api\n",
    "import tensorflow_hub as hub\n",
    "import nlpaug.augmenter.word as naw\n",
    "import random\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModel, AutoTokenizer\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, Word2Vec, KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorboard.plugins import projector\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from tensorboard.plugins import projector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nlpaug.util import Action\n",
    "from scipy import spatial\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Functions ---------- #\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(text):\n",
    "    # Corrected spelling on lower case text\n",
    "    corrected_text = str(TextBlob(text.lower()).correct())\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "# ---------- Loading the dataset ---------- #\n",
    "\n",
    "df = pd.read_csv('/Users/alexandrecogordan/Documents/ESILV/Ongoing/Machine Learning For NLP/Project 2/NLP_Data_Exploration_and_Modeling/yelp_reviews.csv')\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['text', 'rating', 'location'], inplace=True)\n",
    "\n",
    "# ---------- Preprocessing ---------- #\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def review_to_vector(review, model):\n",
    "    words = review.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, model, reviews, topn=10):\n",
    "    query_vector = review_to_vector(query, model)\n",
    "\n",
    "    # Calculate similarity between query and each review\n",
    "    similarities = []\n",
    "\n",
    "    restaurant_set = set()\n",
    "\n",
    "    for review in reviews:\n",
    "        review_vector = review_to_vector(review, model)\n",
    "        similarity = 1 - spatial.distance.cosine(query_vector, review_vector)\n",
    "    \n",
    "        # ## \n",
    "\n",
    "        # Find the row in the df dataframe that corresponds to the review\n",
    "        row = df[df['cleaned_text'] == review]\n",
    "        restaurant_id = row['restaurant_id'].values[0]\n",
    "        \n",
    "        if restaurant_id not in restaurant_set:\n",
    "            similarities.append((review, similarity))\n",
    "            restaurant_set.add(restaurant_id)\n",
    "\n",
    "        # ##\n",
    "\n",
    "        # Replace with this if this doesn't work\n",
    "            \n",
    "        # similarities.append((review, similarity))\n",
    "\n",
    "    # Sort reviews by similarity\n",
    "    sorted_reviews = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the topn most similar reviews\n",
    "    return sorted_reviews[:topn]\n",
    "\n",
    "model = api.load('glove-twitter-50') # Change to 200 when we have the time\n",
    "\n",
    "user_query = \"Food for families and friends\"\n",
    "search_results = semantic_search(user_query, model, df['cleaned_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Been here a few times, in just recent weeks. This doesn't count visits to the rooftop bar so it's time. Time to drop my thoughts of my experiences. Here...\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/alexandrecogordan/Documents/ESILV/Ongoing/Machine Learning For NLP/Project 2/NLP_Data_Exploration_and_Modeling/yelp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_price</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>business_display_address</th>\n",
       "      <th>business_display_phone</th>\n",
       "      <th>business_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBTPC53ZrG1ZBY3DT8Mbcw</td>\n",
       "      <td>I went on a date with my partner and I got som...</td>\n",
       "      <td>5</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Luke</td>\n",
       "      <td>$$$</td>\n",
       "      <td>5069</td>\n",
       "      <td>['333 Saint Charles Ave', 'New Orleans, LA 701...</td>\n",
       "      <td>(504) 378-2840</td>\n",
       "      <td>[{'alias': 'french', 'title': 'French'}, {'ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBTPC53ZrG1ZBY3DT8Mbcw</td>\n",
       "      <td>Went back to Luke for the first time since COV...</td>\n",
       "      <td>4</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Luke</td>\n",
       "      <td>$$$</td>\n",
       "      <td>5069</td>\n",
       "      <td>['333 Saint Charles Ave', 'New Orleans, LA 701...</td>\n",
       "      <td>(504) 378-2840</td>\n",
       "      <td>[{'alias': 'french', 'title': 'French'}, {'ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBTPC53ZrG1ZBY3DT8Mbcw</td>\n",
       "      <td>Luke is my favorite New Orleans restaurant. I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Luke</td>\n",
       "      <td>$$$</td>\n",
       "      <td>5069</td>\n",
       "      <td>['333 Saint Charles Ave', 'New Orleans, LA 701...</td>\n",
       "      <td>(504) 378-2840</td>\n",
       "      <td>[{'alias': 'french', 'title': 'French'}, {'ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Tskf8WK17rb3ZfeFuRSWA</td>\n",
       "      <td>Went here for the Bananas Foster, because of o...</td>\n",
       "      <td>5</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Palace Café</td>\n",
       "      <td>$$$</td>\n",
       "      <td>2017</td>\n",
       "      <td>['605 Canal St', 'New Orleans, LA 70130']</td>\n",
       "      <td>(504) 523-1661</td>\n",
       "      <td>[{'alias': 'cajun', 'title': 'Cajun/Creole'}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Tskf8WK17rb3ZfeFuRSWA</td>\n",
       "      <td>Why have I not eaten here before?! I have usua...</td>\n",
       "      <td>4</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Palace Café</td>\n",
       "      <td>$$$</td>\n",
       "      <td>2017</td>\n",
       "      <td>['605 Canal St', 'New Orleans, LA 70130']</td>\n",
       "      <td>(504) 523-1661</td>\n",
       "      <td>[{'alias': 'cajun', 'title': 'Cajun/Creole'}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>B2-pidnIEJcI4-sy97BJww</td>\n",
       "      <td>Food amazing! Service and integrity 0.  Dined ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Miami</td>\n",
       "      <td>LPM Restaurant &amp; Bar</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>394</td>\n",
       "      <td>['1300 Brickell Bay Dr', 'Miami, FL 33131']</td>\n",
       "      <td>(305) 403-9133</td>\n",
       "      <td>[{'alias': 'french', 'title': 'French'}, {'ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>B2-pidnIEJcI4-sy97BJww</td>\n",
       "      <td>Fun place celebrated my mothers birthday here-...</td>\n",
       "      <td>5</td>\n",
       "      <td>Miami</td>\n",
       "      <td>LPM Restaurant &amp; Bar</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>394</td>\n",
       "      <td>['1300 Brickell Bay Dr', 'Miami, FL 33131']</td>\n",
       "      <td>(305) 403-9133</td>\n",
       "      <td>[{'alias': 'french', 'title': 'French'}, {'ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>K6RzqmTJ5yaI35Bw1BAE3g</td>\n",
       "      <td>I've dined here twice, both times for a work r...</td>\n",
       "      <td>5</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Two Chef's</td>\n",
       "      <td>$$$</td>\n",
       "      <td>143</td>\n",
       "      <td>['8287 S Dixie Hwy', 'Coral Gables, FL 33143']</td>\n",
       "      <td>(305) 663-2100</td>\n",
       "      <td>[{'alias': 'newamerican', 'title': 'New Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>K6RzqmTJ5yaI35Bw1BAE3g</td>\n",
       "      <td>This is two reviews at once having been there ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Two Chef's</td>\n",
       "      <td>$$$</td>\n",
       "      <td>143</td>\n",
       "      <td>['8287 S Dixie Hwy', 'Coral Gables, FL 33143']</td>\n",
       "      <td>(305) 663-2100</td>\n",
       "      <td>[{'alias': 'newamerican', 'title': 'New Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>K6RzqmTJ5yaI35Bw1BAE3g</td>\n",
       "      <td>We used to enjoy going to Two Chefs but had no...</td>\n",
       "      <td>3</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Two Chef's</td>\n",
       "      <td>$$$</td>\n",
       "      <td>143</td>\n",
       "      <td>['8287 S Dixie Hwy', 'Coral Gables, FL 33143']</td>\n",
       "      <td>(305) 663-2100</td>\n",
       "      <td>[{'alias': 'newamerican', 'title': 'New Americ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              restaurant_id  \\\n",
       "0    GBTPC53ZrG1ZBY3DT8Mbcw   \n",
       "1    GBTPC53ZrG1ZBY3DT8Mbcw   \n",
       "2    GBTPC53ZrG1ZBY3DT8Mbcw   \n",
       "3    -Tskf8WK17rb3ZfeFuRSWA   \n",
       "4    -Tskf8WK17rb3ZfeFuRSWA   \n",
       "..                      ...   \n",
       "678  B2-pidnIEJcI4-sy97BJww   \n",
       "679  B2-pidnIEJcI4-sy97BJww   \n",
       "680  K6RzqmTJ5yaI35Bw1BAE3g   \n",
       "681  K6RzqmTJ5yaI35Bw1BAE3g   \n",
       "682  K6RzqmTJ5yaI35Bw1BAE3g   \n",
       "\n",
       "                                                  text  rating     location  \\\n",
       "0    I went on a date with my partner and I got som...       5  New Orleans   \n",
       "1    Went back to Luke for the first time since COV...       4  New Orleans   \n",
       "2    Luke is my favorite New Orleans restaurant. I ...       5  New Orleans   \n",
       "3    Went here for the Bananas Foster, because of o...       5  New Orleans   \n",
       "4    Why have I not eaten here before?! I have usua...       4  New Orleans   \n",
       "..                                                 ...     ...          ...   \n",
       "678  Food amazing! Service and integrity 0.  Dined ...       1        Miami   \n",
       "679  Fun place celebrated my mothers birthday here-...       5        Miami   \n",
       "680  I've dined here twice, both times for a work r...       5        Miami   \n",
       "681  This is two reviews at once having been there ...       4        Miami   \n",
       "682  We used to enjoy going to Two Chefs but had no...       3        Miami   \n",
       "\n",
       "            business_name business_price  business_review_count  \\\n",
       "0                    Luke            $$$                   5069   \n",
       "1                    Luke            $$$                   5069   \n",
       "2                    Luke            $$$                   5069   \n",
       "3             Palace Café            $$$                   2017   \n",
       "4             Palace Café            $$$                   2017   \n",
       "..                    ...            ...                    ...   \n",
       "678  LPM Restaurant & Bar           $$$$                    394   \n",
       "679  LPM Restaurant & Bar           $$$$                    394   \n",
       "680            Two Chef's            $$$                    143   \n",
       "681            Two Chef's            $$$                    143   \n",
       "682            Two Chef's            $$$                    143   \n",
       "\n",
       "                              business_display_address business_display_phone  \\\n",
       "0    ['333 Saint Charles Ave', 'New Orleans, LA 701...         (504) 378-2840   \n",
       "1    ['333 Saint Charles Ave', 'New Orleans, LA 701...         (504) 378-2840   \n",
       "2    ['333 Saint Charles Ave', 'New Orleans, LA 701...         (504) 378-2840   \n",
       "3            ['605 Canal St', 'New Orleans, LA 70130']         (504) 523-1661   \n",
       "4            ['605 Canal St', 'New Orleans, LA 70130']         (504) 523-1661   \n",
       "..                                                 ...                    ...   \n",
       "678        ['1300 Brickell Bay Dr', 'Miami, FL 33131']         (305) 403-9133   \n",
       "679        ['1300 Brickell Bay Dr', 'Miami, FL 33131']         (305) 403-9133   \n",
       "680     ['8287 S Dixie Hwy', 'Coral Gables, FL 33143']         (305) 663-2100   \n",
       "681     ['8287 S Dixie Hwy', 'Coral Gables, FL 33143']         (305) 663-2100   \n",
       "682     ['8287 S Dixie Hwy', 'Coral Gables, FL 33143']         (305) 663-2100   \n",
       "\n",
       "                                   business_categories  \n",
       "0    [{'alias': 'french', 'title': 'French'}, {'ali...  \n",
       "1    [{'alias': 'french', 'title': 'French'}, {'ali...  \n",
       "2    [{'alias': 'french', 'title': 'French'}, {'ali...  \n",
       "3    [{'alias': 'cajun', 'title': 'Cajun/Creole'}, ...  \n",
       "4    [{'alias': 'cajun', 'title': 'Cajun/Creole'}, ...  \n",
       "..                                                 ...  \n",
       "678  [{'alias': 'french', 'title': 'French'}, {'ali...  \n",
       "679  [{'alias': 'french', 'title': 'French'}, {'ali...  \n",
       "680  [{'alias': 'newamerican', 'title': 'New Americ...  \n",
       "681  [{'alias': 'newamerican', 'title': 'New Americ...  \n",
       "682  [{'alias': 'newamerican', 'title': 'New Americ...  \n",
       "\n",
       "[683 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
