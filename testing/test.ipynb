{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:121: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"best_of\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:140: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"repetition_penalty\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:146: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"seed\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:152: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"temperature\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:158: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"top_k\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:164: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"top_p\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:170: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"truncate\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:176: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"typical_p\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:204: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"inputs\")\n",
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/inference/_text_generation.py:210: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"stream\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  rating     location  \\\n",
      "0   Robyn gave amazing service! So attentive and f...       5  Los Angeles   \n",
      "1   Headed downtown on a Thursday evening for a Ki...       5  Los Angeles   \n",
      "2   Been here a few times, in just recent weeks. T...       4  Los Angeles   \n",
      "3   Service is fast. Staff is friendly. The food i...       5  Los Angeles   \n",
      "4   Walked by and asked to see a menu. Very helpfu...       3  Los Angeles   \n",
      "5   My husband and I had a fabulous dining experie...       5  Los Angeles   \n",
      "6   Morgen was literally amazing, top tier food, t...       5  Los Angeles   \n",
      "7   ADKT in West Hollywood is an absolute gem that...       5  Los Angeles   \n",
      "8   I enjoyed our time at ADKT and the food was de...       3  Los Angeles   \n",
      "9   This a charming family run restaurant. The own...       5  Los Angeles   \n",
      "10  Ahhh... we left with our hearts and bellies so...       5  Los Angeles   \n",
      "11  A Food Affair has a nice charm and the service...       4  Los Angeles   \n",
      "12  This is a cute intimate restaurant.  I love th...       5  Los Angeles   \n",
      "13  生活的本質就是快樂，如果日子都過得不快樂，那人生還有什麼意義，年底了，是不是該好好清清自己的...       5  Los Angeles   \n",
      "14  Since we haven't been in Paris in a few years,...       5  Los Angeles   \n",
      "\n",
      "                                               tokens  \\\n",
      "0   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "1   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "2   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "3   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "4   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "5   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "6   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "7   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "8   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "9   [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "10  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "11  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "12  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "13  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "14  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
      "\n",
      "                                         cleaned_text  \n",
      "0   Robin gave amazing service! To attentive and f...  \n",
      "1   Headed downtown on a Thursday evening for a Ki...  \n",
      "2   Been here a few times, in just recent weeks. H...  \n",
      "3   Service is fast. Staff is friendly. The food i...  \n",
      "4   Talked by and asked to see a menu. Very helpfu...  \n",
      "5   By husband and I had a fabulous dining experie...  \n",
      "6   Morgen was literally amazing, top tier food, t...  \n",
      "7   ADKT in West Hollywood is an absolute gem that...  \n",
      "8   I enjoyed our time at ADKT and the food was de...  \n",
      "9   His a charming family run restaurant. The owne...  \n",
      "10  Heh... we left with our hearts and bellies so ...  \n",
      "11  A Good Affair has a nice charm and the service...  \n",
      "12  His is a cut intimate restaurant.  I love the ...  \n",
      "13  The essence of life is happiness. If life is n...  \n",
      "14  Since we haven't been in Paris in a few years,...  \n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Parameters ---------- #\n",
    "\n",
    "max_length_coef = 1.5\n",
    "min_length_coef = 2\n",
    "\n",
    "# ---------- Functions ---------- #\n",
    "\n",
    "# ---------- Loading the dataset ---------- #\n",
    "\n",
    "df = pd.read_csv('current_yelp_reviews.csv')[0:15]\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['text', 'rating', 'location'], inplace=True)\n",
    "\n",
    "# ---------- Preprocessing ---------- #\n",
    "\n",
    "# Translation pipeline\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Check if text contains Chinese characters\n",
    "def contains_chinese(text):\n",
    "    return bool(re.search('[\\u4e00-\\u9fff]', text))\n",
    "\n",
    "# Translation function (from Chinese to English)\n",
    "def translate_text(text):\n",
    "    if contains_chinese(text):\n",
    "        return translator(text)[0]['translation_text']\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "# Lemmatisation & Tokenisation function\n",
    "def tokenisation(reviews, allowed_postags=[\"NOUN\", \"ADJ\", \"VERBS\", \"ADV\"]):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "    reviews_out = []\n",
    "    tokens = []\n",
    "\n",
    "    for review in reviews:\n",
    "        doc = nlp(review) \n",
    "        reviews_out.append(\" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags and token.lemma_ not in stop_words]))\n",
    "\n",
    "    for text in reviews_out:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=False)\n",
    "        tokens.append(new)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(text):\n",
    "    # Corrected spelling\n",
    "    corrected_text = str(TextBlob(text).correct())\n",
    "\n",
    "    # Translation\n",
    "    cleaned_text = translate_text(str(corrected_text))\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def tokenised_text(text):\n",
    "    # Lower case\n",
    "    lower_text = text.lower()\n",
    "\n",
    "    # Lemmatization & Tokenisation\n",
    "    tokens = tokenisation(lower_text)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing and tokenisation\n",
    "df['cleaned_text'] = df['text'].apply(preprocessing)\n",
    "df['tokens'] = df['cleaned_text'].apply(tokenised_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
