{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import torch\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Parameters ---------- #\n",
    "\n",
    "max_length_coef = 1.5\n",
    "min_length_coef = 2\n",
    "\n",
    "# ---------- Functions ---------- #\n",
    "\n",
    "# ---------- Loading the dataset ---------- #\n",
    "\n",
    "df = pd.read_csv('yelp_reviews.csv')\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['text', 'rating', 'location'], inplace=True)\n",
    "\n",
    "# ---------- Preprocessing ---------- #\n",
    "\n",
    "# Translation pipeline\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Check if text contains Chinese characters\n",
    "def contains_chinese(text):\n",
    "    return bool(re.search('[\\u4e00-\\u9fff]', text))\n",
    "\n",
    "# Translation function (from Chinese to English)\n",
    "def translate_text(text):\n",
    "    if contains_chinese(text):\n",
    "        return translator(text)[0]['translation_text']\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation & Tokenisation function\n",
    "def tokenisation(reviews, allowed_postags=[\"NOUN\", \"ADJ\", \"VERBS\", \"ADV\"]):\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "    reviews_out = []\n",
    "    tokens = []\n",
    "\n",
    "    for review in reviews:\n",
    "        doc = nlp(review) \n",
    "        reviews_out.append(\" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags and token.lemma_ not in stop_words]))\n",
    "    \n",
    "    for text in reviews_out:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=False) # We do not remove the accent marks because we deem them important for French restaurants reviews\n",
    "        tokens.append(new)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(text):\n",
    "    # Corrected spelling on lower case text\n",
    "    corrected_text = str(TextBlob(text.lower()).correct())\n",
    "\n",
    "    # Translation\n",
    "    cleaned_text = translate_text(str(corrected_text))\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply preprocessing and tokenisation\n",
    "df['cleaned_text'] = df['text'].apply(preprocessing)\n",
    "df['tokens'] = tokenisation(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarisation\n",
    "summariser = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summarised_text = df['text'].apply(lambda x: summariser(x, max_length=round(len(x)/max_length_coef), min_length=round(len(x)/min_length_coef), do_sample=False))\n",
    "df['summarised_text'] = summarised_text.apply(lambda x: x[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['restaurant_id'] = [(i // 10) + 1 for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Highlighting frequent words ---------- #\n",
    "\n",
    "review_frequent_words = {}\n",
    "\n",
    "def get_frequency(restaurant_id):\n",
    "\n",
    "    # Word Frequency Analysis\n",
    "    all_words = [word for tokens in df[df['restaurant_id'] == restaurant_id]['tokens'] for word in tokens]\n",
    "    word_freq = Counter(all_words)\n",
    "\n",
    "    # N-gram Analysis\n",
    "    bigrams = ngrams(all_words, 2)\n",
    "    bigram_freq = Counter(bigrams)\n",
    "\n",
    "    # Tri-gram Analysis\n",
    "    trigrams = ngrams(all_words, 3)\n",
    "    trigram_freq = Counter(trigrams)\n",
    "\n",
    "    return [word_freq, bigram_freq, trigram_freq]\n",
    "\n",
    "for restaurant_id in df['restaurant_id']:\n",
    "    review_frequent_words[restaurant_id] = get_frequency(restaurant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq</th>\n",
       "      <th>bigram_freq</th>\n",
       "      <th>trigram_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'time': 5, 'service': 3, 'food': 3, 'amazing'...</td>\n",
       "      <td>{('amazing', 'service'): 1, ('service', 'atten...</td>\n",
       "      <td>{('amazing', 'service', 'attentive'): 1, ('ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'food': 6, 'service': 4, 'life': 3, 'heart': ...</td>\n",
       "      <td>{('heart', 'belly'): 1, ('belly', 'happily'): ...</td>\n",
       "      <td>{('heart', 'belly', 'happily'): 1, ('belly', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'food': 6, 'service': 5, 'time': 4, 'great': ...</td>\n",
       "      <td>{('review', 'private'): 1, ('private', 'party'...</td>\n",
       "      <td>{('review', 'private', 'party'): 1, ('private'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'restaurant': 3, 'food': 3, 'pm': 3, 'great':...</td>\n",
       "      <td>{('present', 'thoughtful'): 1, ('thoughtful', ...</td>\n",
       "      <td>{('present', 'thoughtful', 'son'): 1, ('though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'service': 3, 'food': 3, 'experience': 3, 'go...</td>\n",
       "      <td>{('great', 'thing'): 1, ('thing', 'place'): 1,...</td>\n",
       "      <td>{('great', 'thing', 'place'): 1, ('thing', 'pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>{'service': 7, 'amazing': 4, 'experience': 3, ...</td>\n",
       "      <td>{('demand', 'river'): 1, ('river', 'floor'): 1...</td>\n",
       "      <td>{('demand', 'river', 'floor'): 1, ('river', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>{'dining': 4, 'experience': 3, 'art': 3, 'love...</td>\n",
       "      <td>{('ten', 'board'): 1, ('board', 'honestly'): 1...</td>\n",
       "      <td>{('ten', 'board', 'honestly'): 1, ('board', 'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>{'food': 4, 'alliance': 4, 'server': 3, 'great...</td>\n",
       "      <td>{('service', 'recent'): 1, ('recent', 'server'...</td>\n",
       "      <td>{('service', 'recent', 'server'): 1, ('recent'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>{'service': 4, 'friendly': 3, 'course': 3, 're...</td>\n",
       "      <td>{('kid', 'friendly'): 1, ('friendly', 'actuall...</td>\n",
       "      <td>{('kid', 'friendly', 'actually'): 1, ('friendl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>{'service': 5, 'food': 3, 'alliance': 3, 'amaz...</td>\n",
       "      <td>{('first', 'time'): 1, ('time', 'camelback'): ...</td>\n",
       "      <td>{('first', 'time', 'camelback'): 1, ('time', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            word_freq  \\\n",
       "1   {'time': 5, 'service': 3, 'food': 3, 'amazing'...   \n",
       "2   {'food': 6, 'service': 4, 'life': 3, 'heart': ...   \n",
       "3   {'food': 6, 'service': 5, 'time': 4, 'great': ...   \n",
       "4   {'restaurant': 3, 'food': 3, 'pm': 3, 'great':...   \n",
       "5   {'service': 3, 'food': 3, 'experience': 3, 'go...   \n",
       "..                                                ...   \n",
       "58  {'service': 7, 'amazing': 4, 'experience': 3, ...   \n",
       "59  {'dining': 4, 'experience': 3, 'art': 3, 'love...   \n",
       "60  {'food': 4, 'alliance': 4, 'server': 3, 'great...   \n",
       "61  {'service': 4, 'friendly': 3, 'course': 3, 're...   \n",
       "62  {'service': 5, 'food': 3, 'alliance': 3, 'amaz...   \n",
       "\n",
       "                                          bigram_freq  \\\n",
       "1   {('amazing', 'service'): 1, ('service', 'atten...   \n",
       "2   {('heart', 'belly'): 1, ('belly', 'happily'): ...   \n",
       "3   {('review', 'private'): 1, ('private', 'party'...   \n",
       "4   {('present', 'thoughtful'): 1, ('thoughtful', ...   \n",
       "5   {('great', 'thing'): 1, ('thing', 'place'): 1,...   \n",
       "..                                                ...   \n",
       "58  {('demand', 'river'): 1, ('river', 'floor'): 1...   \n",
       "59  {('ten', 'board'): 1, ('board', 'honestly'): 1...   \n",
       "60  {('service', 'recent'): 1, ('recent', 'server'...   \n",
       "61  {('kid', 'friendly'): 1, ('friendly', 'actuall...   \n",
       "62  {('first', 'time'): 1, ('time', 'camelback'): ...   \n",
       "\n",
       "                                         trigram_freq  \n",
       "1   {('amazing', 'service', 'attentive'): 1, ('ser...  \n",
       "2   {('heart', 'belly', 'happily'): 1, ('belly', '...  \n",
       "3   {('review', 'private', 'party'): 1, ('private'...  \n",
       "4   {('present', 'thoughtful', 'son'): 1, ('though...  \n",
       "5   {('great', 'thing', 'place'): 1, ('thing', 'pl...  \n",
       "..                                                ...  \n",
       "58  {('demand', 'river', 'floor'): 1, ('river', 'f...  \n",
       "59  {('ten', 'board', 'honestly'): 1, ('board', 'h...  \n",
       "60  {('service', 'recent', 'server'): 1, ('recent'...  \n",
       "61  {('kid', 'friendly', 'actually'): 1, ('friendl...  \n",
       "62  {('first', 'time', 'camelback'): 1, ('time', '...  \n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_frequent_words_df = pd.DataFrame.from_dict(review_frequent_words, orient='index', columns=['word_freq', 'bigram_freq', 'trigram_freq'])\n",
    "# review_frequent_words_df['word_freq'] = review_frequent_words_df['word_freq'].apply(lambda x: dict(sorted(x.items(), key=lambda item: item[1], reverse=True)))\n",
    "review_frequent_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el86317122888631202632787566\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el86317122888631202632787566_data = {\"mdsDat\": {\"x\": [0.39425905455194066, 0.09009589925450281, -0.23664328063543053, -0.24304431291986833, 0.09828469778129069, -0.05284493692450437, -0.0930052796017752, -0.2728443060560079, 0.2223149033644846, 0.09342756118536749], \"y\": [0.149253718724891, 0.30300515201646344, 0.02605960347576295, 0.24535274375807586, -0.33371467355171025, 0.18013771696442438, -0.25200066799470394, -0.15465084833732679, -0.1568784023824518, -0.006564342673424759], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [38.37367098418325, 12.396911413431784, 8.166624833927779, 6.893577819714761, 6.886240894601893, 6.783201540678463, 6.511887628272792, 5.85787973881224, 4.671009403313952, 3.458995743063086]}, \"tinfo\": {\"Term\": [\"service\", \"food\", \"birthday\", \"restaurant\", \"time\", \"experience\", \"atmosphere\", \"course\", \"good\", \"table\", \"service\", \"food\", \"great\", \"alliance\", \"place\", \"nice\", \"wine\", \"wonderful\", \"delicious\", \"well\", \"good\", \"night\", \"restaurant\", \"amazing\", \"meal\", \"little\", \"dish\", \"special\", \"many\", \"day\", \"waiter\", \"fresh\", \"rude\", \"martin\", \"reservation\", \"dinner\", \"french\", \"experience\", \"parking\", \"option\", \"potato\", \"small\", \"location\", \"olive\", \"classic\", \"dine\", \"melon\", \"prosciutto\", \"speak\", \"dining\", \"menu\", \"soup\", \"onion\", \"experience\", \"french\", \"course\", \"thing\", \"life\", \"party\", \"urinary\", \"glass\", \"etouffee\", \"profiterole\", \"third\", \"journey\", \"table\", \"server\", \"birthday\", \"family\", \"warm\", \"super\", \"week\", \"excited\", \"right\", \"copy\", \"celebration\", \"close\", \"fun\", \"time\", \"really\", \"overall\", \"kiss\", \"attentive\", \"fantastic\", \"town\", \"upside\", \"downside\", \"pithivier\", \"city\", \"bread\", \"experience\", \"table\", \"branch\", \"year\", \"last\", \"second\", \"tonight\", \"truly\", \"brasserie\", \"new\", \"son\", \"sick\", \"busy\", \"still\", \"star\", \"time\", \"first\", \"favorite\", \"area\", \"bit\", \"high\", \"mummy\", \"disappointed\", \"kid\", \"extremely\", \"ever\", \"atmosphere\", \"selection\", \"lovely\", \"escargot\", \"surprised\", \"event\", \"hard\", \"interesting\", \"overdue\", \"salmon\", \"anywhere\", \"cave\", \"creek\", \"favorite\", \"back\", \"way\", \"incredible\", \"class\", \"wall\", \"mood\", \"shelf\", \"lighting\", \"pass\", \"enough\", \"moment\", \"highly\", \"server\"], \"Freq\": [173.0, 169.0, 34.0, 131.0, 60.0, 53.0, 30.0, 27.0, 100.0, 32.0, 172.98332675803064, 168.79411340870442, 79.38500081310895, 63.713413007964625, 64.01137865373067, 42.80972989362263, 41.695085238100326, 37.22107358901608, 36.67443735662864, 26.643497735517162, 94.91347676872395, 52.06349254300194, 118.12247928890199, 54.40303033081273, 26.59803410271131, 16.6881974658797, 15.832407882768337, 14.70171652025367, 14.47652593987731, 14.215190029322457, 13.340330060856617, 12.621563570011244, 12.180868254853305, 10.738250026568558, 17.12754401104946, 26.985644161990948, 20.503039171394175, 15.774021349697295, 12.454412611481274, 11.420432362061748, 9.767685768691939, 9.161217322148598, 8.750987178224628, 8.546544347628322, 8.134566188899726, 7.880562878566908, 7.880562878566908, 7.880562878566908, 21.129860645382376, 20.627885471621614, 18.95456997774681, 14.037951113612122, 13.354809700608993, 14.9705671022882, 10.053440780186662, 26.80310824255389, 14.113172300886838, 13.221343818338747, 12.47696451178629, 9.078262151050613, 8.833006947390468, 6.884495593198123, 6.884495593198123, 6.884495593198123, 6.884075143061017, 21.17329197118552, 9.510868197101493, 33.7526758402789, 16.113758378130612, 13.39132174982685, 12.087345375315287, 11.56706946537342, 11.3475454505296, 10.750340371631072, 8.35980688734721, 7.981855821591169, 7.62547726018886, 8.602164203962984, 16.92316663626922, 14.648658093608114, 18.995535942126697, 17.000414552194307, 15.014404292768665, 12.838043262056148, 10.504870623294629, 8.45974144510377, 7.0456194900896865, 7.045351195447759, 6.903959141486136, 6.377649819577166, 22.74758440589101, 11.004532454767944, 7.501974678027698, 21.267948930361037, 18.97911947392199, 11.223199678754806, 10.123695051539366, 9.43632697810078, 9.369880842724985, 8.43798579504152, 7.72604691828745, 7.490691441330206, 5.558899751523678, 8.875236648269425, 11.14042924873583, 15.134035120054998, 11.4666553385017, 10.191543227770365, 16.953492584169737, 14.13390927539523, 13.246982663155427, 11.59223842274008, 8.498383971991759, 7.463705430592288, 5.846958592065638, 5.468598383191893, 27.452682643001033, 4.459015158342307, 9.599888216831284, 14.145516731887136, 8.304562082398968, 7.5509884788063, 6.950859848540039, 6.453569804950134, 6.1314552620236205, 6.023766010801109, 5.704405068790507, 5.704405068790507, 5.704405068790507, 16.38477048706107, 6.355029234794801, 11.356390312585077, 9.598523543150376, 8.718318789107029, 6.977724559398834, 6.533668088943122, 6.2059335840695695, 5.771429832170928, 5.770974185459895, 5.546784106850667, 2.8781541152216206, 3.6514825512111773, 3.994794304523449], \"Total\": [173.0, 169.0, 34.0, 131.0, 60.0, 53.0, 30.0, 27.0, 100.0, 32.0, 173.6280451739908, 169.4390139344442, 80.02972414525661, 64.35809991080254, 64.68226773864185, 43.45467666467171, 42.339752775615494, 37.865723233652744, 37.31916913480532, 27.28819136915734, 100.35631261555343, 54.06897312168821, 131.49340583527186, 58.958719591393866, 27.486952292368326, 17.333205992866084, 16.480982413183373, 15.34674755500077, 15.121787464596462, 14.860206098946534, 13.985554929810293, 13.267176721606601, 12.826219729682956, 11.383440283485191, 22.2796594658082, 73.76317660407064, 71.46806880147228, 53.98792752581204, 13.11575272094649, 12.081538670132328, 10.42896540049282, 9.822307970008676, 9.4120653994297, 9.207957161696008, 8.795621782705298, 8.541661469074276, 8.541661469074276, 8.541661469074276, 24.121768943888387, 33.29020468322175, 32.782989036770196, 23.187885402569098, 23.040263117619688, 53.98792752581204, 71.46806880147228, 27.474115364140342, 14.784312565651899, 13.892432292233531, 13.148153864411977, 9.749301070159564, 9.504028224601488, 7.555520263685204, 7.555520263685204, 7.555520263685204, 7.555199069308632, 32.77850348395657, 19.337115638650836, 34.42522925337534, 16.786271407406083, 14.063871547490143, 12.759843677580387, 12.23960918440296, 12.020100913913932, 11.42312698250675, 9.03233273262058, 8.654352854284898, 8.29798209585519, 10.780928302572201, 60.062164876883536, 50.546246959477514, 19.665034835040323, 17.66988191433738, 15.683817209210568, 13.507554083568456, 11.174452405309447, 9.129157704085593, 7.715163482242422, 7.7148949644156835, 7.57339890946754, 7.0470657859199, 53.98792752581204, 32.77850348395657, 17.4573439630346, 21.93293759897039, 19.64407222185938, 11.88828268363836, 10.788889190335437, 10.101310706885668, 10.03485445275163, 9.102941873248271, 8.391669062403261, 8.155732533688568, 6.223902052285361, 10.806544202116724, 16.813672695843042, 60.062164876883536, 39.869767086994116, 27.184341279731854, 17.618776631123314, 14.799221596210376, 13.91220474496928, 12.257601075904162, 9.163990088873193, 8.129245099401482, 6.512174157216205, 6.133843904105462, 30.872485618099766, 5.124309696896033, 22.06681792512914, 14.828554798664847, 8.987363850117196, 8.233910196412056, 7.633906352623251, 7.1368090968275935, 6.8147686680369475, 6.707015816234534, 6.387178030918561, 6.387178030918561, 6.387178030918561, 27.184341279731854, 10.1424514180617, 12.038592369771875, 10.28084819254, 9.400652399239835, 7.659866592042915, 7.215886924440719, 6.888108126136962, 6.453654481477783, 6.453294771395485, 6.2289480355398394, 3.5602990186699164, 6.920978527232652, 19.337115638650836], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.614, -2.6385, -3.3929, -3.6128, -3.6082, -4.0105, -4.0368, -4.1503, -4.1651, -4.4847, -3.2143, -3.8148, -2.9955, -3.7708, -3.3565, -3.8226, -3.8752, -3.9493, -3.9648, -3.983, -4.0465, -4.1019, -4.1374, -4.2635, -3.7966, -3.342, -3.6167, -3.8789, -3.6978, -3.7845, -3.9408, -4.0049, -4.0507, -4.0744, -4.1238, -4.1555, -4.1555, -4.1555, -3.1692, -3.1933, -3.2779, -3.5781, -3.628, -3.5138, -3.912, -2.7619, -3.4033, -3.4686, -3.5266, -3.8446, -3.8719, -4.1212, -4.1212, -4.1212, -4.1212, -2.9977, -3.798, -2.5303, -3.2697, -3.4548, -3.5572, -3.6012, -3.6204, -3.6744, -3.9259, -3.9722, -4.0179, -3.8974, -3.2207, -3.365, -3.0901, -3.2011, -3.3253, -3.4819, -3.6825, -3.899, -4.0819, -4.0819, -4.1022, -4.1815, -2.9098, -3.636, -4.0191, -2.9363, -3.0501, -3.5755, -3.6786, -3.7489, -3.756, -3.8607, -3.9489, -3.9798, -4.2781, -3.8102, -3.5829, -3.2765, -3.554, -3.6719, -3.0572, -3.2391, -3.3039, -3.4373, -3.7478, -3.8776, -4.1217, -4.1886, -2.5752, -4.3927, -3.6259, -3.0118, -3.5444, -3.6395, -3.7224, -3.7966, -3.8478, -3.8655, -3.92, -3.92, -3.92, -2.8649, -3.812, -2.931, -3.0992, -3.1954, -3.4181, -3.4839, -3.5353, -3.6079, -3.608, -3.6476, -4.3037, -4.0657, -3.9758], \"loglift\": [10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9541, 0.954, 0.9497, 0.9477, 0.9474, 0.9428, 0.9425, 0.9406, 0.9404, 0.9339, 0.902, 0.92, 0.8506, 0.8774, 2.0548, 2.0498, 2.0476, 2.0448, 2.0441, 2.0433, 2.0405, 2.0378, 2.0361, 2.0294, 1.8247, 1.0822, 0.839, 0.8573, 2.4534, 2.4488, 2.4396, 2.4354, 2.4323, 2.4306, 2.427, 2.4246, 2.4246, 2.4246, 2.3727, 2.0265, 1.9572, 2.0032, 1.9597, 1.2224, 0.5438, 2.6499, 2.6281, 2.6251, 2.6222, 2.6033, 2.6014, 2.5816, 2.5816, 2.5816, 2.5816, 2.2375, 1.965, 2.6559, 2.6348, 2.6266, 2.6215, 2.6191, 2.6181, 2.6149, 2.5983, 2.5948, 2.5911, 2.4499, 1.4089, 1.4371, 2.6561, 2.6521, 2.6471, 2.6399, 2.6289, 2.6146, 2.5999, 2.5999, 2.5982, 2.5909, 1.8264, 1.5993, 1.8461, 2.7008, 2.6971, 2.674, 2.6679, 2.6634, 2.663, 2.6557, 2.6489, 2.6465, 2.6185, 2.5347, 2.3199, 1.3531, 1.4854, 1.7505, 2.7989, 2.7914, 2.7884, 2.7816, 2.762, 2.752, 2.7296, 2.7226, 2.72, 2.6983, 2.0051, 3.0166, 2.9848, 2.9772, 2.9701, 2.9632, 2.9581, 2.9564, 2.9507, 2.9507, 2.9507, 2.5575, 2.5963, 3.3059, 3.2955, 3.2888, 3.2709, 3.2649, 3.2599, 3.2525, 3.2524, 3.2482, 3.1515, 2.7248, 1.7872]}, \"token.table\": {\"Topic\": [1, 1, 6, 9, 8, 3, 8, 6, 4, 9, 5, 8, 2, 6, 7, 6, 7, 9, 5, 6, 10, 3, 5, 5, 4, 9, 2, 1, 3, 2, 3, 1, 2, 3, 4, 6, 8, 2, 6, 10, 9, 4, 9, 8, 5, 2, 3, 6, 8, 5, 6, 7, 9, 1, 7, 1, 1, 2, 3, 2, 5, 9, 4, 1, 3, 1, 9, 8, 8, 10, 10, 9, 4, 8, 6, 7, 4, 10, 2, 3, 2, 8, 2, 2, 2, 3, 2, 3, 9, 10, 10, 8, 7, 1, 1, 6, 3, 2, 3, 3, 6, 9, 3, 4, 10, 6, 1, 3, 4, 3, 1, 2, 5, 2, 4, 1, 3, 7, 5, 2, 9, 7, 8, 4, 6, 10, 1, 10, 7, 3, 7, 2, 3, 3, 8, 2, 7, 8, 3, 7, 5, 9, 4, 6, 4, 4, 1, 5, 7, 7, 6, 7, 6, 4, 2, 10, 5, 10, 5, 1, 1, 1, 7], \"Freq\": [0.9944358221995546, 0.9158950597000807, 0.06784407849630227, 0.9393819885645368, 0.9648797050965359, 0.09717390549989195, 0.8745651494990275, 0.956399822818071, 0.29578647965299526, 0.5915729593059905, 0.9876477437449847, 0.9459957004485268, 0.5155423424695778, 0.45825985997295804, 0.8968739947725037, 0.8514181905308807, 0.9640254537419743, 0.9393819885645368, 0.9243903194955914, 0.9242877714059494, 0.9573803623169566, 0.9095434294060122, 0.9640898121479401, 0.8857069637290625, 0.9827431981755756, 0.9393819885645368, 0.9421134476050426, 0.9914475819744966, 0.9365859357649092, 0.3604663928680497, 0.630816187519087, 0.44737769601667193, 0.36603629674091337, 0.09489829915505162, 0.013556899879293089, 0.06778449939646544, 0.8729821750586029, 0.9708159136922185, 0.9073041700427378, 0.9632445102714687, 0.9441243728795844, 0.9264749157837281, 0.9715918450854634, 0.815149533990168, 0.915133747942739, 0.29636255239377873, 0.27783989286916755, 0.4260211690660569, 0.9213512807164931, 0.9531598537684085, 0.9624244270703398, 0.3678588308283128, 0.5885741293253005, 0.7022865204831823, 0.2758982759041073, 0.9974090150535575, 0.5596905117320866, 0.2938375186593455, 0.13992262793302165, 0.9798618253745363, 0.8348075181849328, 0.18551278181887396, 0.9469668847050776, 0.9466270484042943, 0.04982247623180497, 0.987133228856473, 0.9169617331753852, 0.9344313312166328, 0.4334647171921725, 0.57795295625623, 0.9726823908611169, 0.8407118529577987, 0.9265143030361691, 0.8610885653472765, 0.9620890554003172, 0.9672128968685691, 0.935761263869363, 0.9297057995931162, 0.9807764361074793, 0.956219450041787, 0.5438029189670659, 0.4531690991392216, 0.9258164772370449, 0.9663159577477226, 0.9822842384565302, 0.9365859357649092, 0.2745326239137432, 0.5795688727067912, 0.12201449951721921, 0.8426258536904473, 0.9700817201403898, 0.9789843808499731, 0.8788367663326955, 0.9895367610676216, 0.9617345586158672, 0.01849489535799745, 0.9774154942248119, 0.39062053909954647, 0.5642296675882338, 0.910480055590429, 0.9661818633621068, 0.880440744546704, 0.9149303326552826, 0.9126756595448979, 0.9297576218887855, 0.9073357488711022, 0.9894520127000084, 0.9588678853539443, 0.9264749157837281, 0.9365859357649092, 0.6330836001662818, 0.07913545002078523, 0.2967579375779446, 0.7630278203349244, 0.22441994715733074, 0.8973834029960734, 0.03041977637274825, 0.06844449683868356, 0.9629587429821342, 0.9355835353599249, 0.894585634564454, 0.9252808242135016, 0.7805929455089209, 0.5171402078194174, 0.2585701039097087, 0.20685608312776696, 0.9963828126190014, 0.8710664655847908, 0.8582920014953129, 0.9162815936417895, 0.9533264408438084, 0.38813371050224554, 0.6037635496701598, 0.870582918228336, 0.08291265887888914, 0.9774057953479673, 0.6542294594993279, 0.297377027045149, 0.09253652058390005, 0.8328286852551005, 0.9404503929060302, 0.8901386583893206, 0.6406637816847998, 0.3355857904063237, 0.9469496764107872, 0.9264749157837281, 0.44953424598239283, 0.28304008080372883, 0.24974124776799603, 0.9268794797668221, 0.984388281503033, 0.8909734846454186, 0.8763130465387559, 0.9231430986931968, 0.929530509532405, 0.913854035953004, 0.9243542900759782, 0.9137280889766055, 0.9804234611748637, 0.9894389714122619, 0.9919755607120322, 0.9771370210385063, 0.9574640836522424], \"Term\": [\"alliance\", \"amazing\", \"amazing\", \"anywhere\", \"area\", \"atmosphere\", \"atmosphere\", \"attentive\", \"back\", \"back\", \"birthday\", \"bit\", \"branch\", \"branch\", \"brasserie\", \"bread\", \"busy\", \"cave\", \"celebration\", \"city\", \"class\", \"classic\", \"close\", \"copy\", \"course\", \"creek\", \"day\", \"delicious\", \"dine\", \"dining\", \"dining\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"disappointed\", \"dish\", \"downside\", \"enough\", \"escargot\", \"etouffee\", \"event\", \"ever\", \"excited\", \"experience\", \"experience\", \"experience\", \"extremely\", \"family\", \"fantastic\", \"favorite\", \"favorite\", \"first\", \"first\", \"food\", \"french\", \"french\", \"french\", \"fresh\", \"fun\", \"fun\", \"glass\", \"good\", \"good\", \"great\", \"hard\", \"high\", \"highly\", \"highly\", \"incredible\", \"interesting\", \"journey\", \"kid\", \"kiss\", \"last\", \"life\", \"lighting\", \"little\", \"location\", \"lovely\", \"lovely\", \"many\", \"martin\", \"meal\", \"melon\", \"menu\", \"menu\", \"menu\", \"moment\", \"mood\", \"mummy\", \"new\", \"nice\", \"night\", \"night\", \"olive\", \"onion\", \"onion\", \"option\", \"overall\", \"overdue\", \"parking\", \"party\", \"pass\", \"pithivier\", \"place\", \"potato\", \"profiterole\", \"prosciutto\", \"really\", \"really\", \"really\", \"reservation\", \"reservation\", \"restaurant\", \"restaurant\", \"restaurant\", \"right\", \"rude\", \"salmon\", \"second\", \"selection\", \"server\", \"server\", \"server\", \"service\", \"shelf\", \"sick\", \"small\", \"son\", \"soup\", \"soup\", \"speak\", \"speak\", \"special\", \"star\", \"star\", \"still\", \"still\", \"super\", \"surprised\", \"table\", \"table\", \"thing\", \"third\", \"time\", \"time\", \"time\", \"tonight\", \"town\", \"truly\", \"upside\", \"urinary\", \"waiter\", \"wall\", \"warm\", \"way\", \"week\", \"well\", \"wine\", \"wonderful\", \"year\"]}, \"R\": 10, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 10, 4, 5, 7, 1, 8, 9, 2, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el86317122888631202632787566\", ldavis_el86317122888631202632787566_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el86317122888631202632787566\", ldavis_el86317122888631202632787566_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el86317122888631202632787566\", ldavis_el86317122888631202632787566_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- Topic Modelling ---------- #\n",
    "\n",
    "# We convert the tokens into tuples where we'll have the word index (its placement on the map) and its frequency\n",
    "id2word = corpora.Dictionary(df['tokens'])\n",
    "corpus = [id2word.doc2bow(text) for text in df['tokens']]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=10,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "pyLDAvis.enable_notebook(local=True)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds', R=10)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_distribution(lda_model, bow):\n",
    "    return lda_model.get_document_topics(bow, minimum_probability=0)\n",
    "\n",
    "df['topic_distribution'] = [get_topic_distribution(lda_model, corpus[i]) for i in range(len(df))]\n",
    "\n",
    "def get_top_topics(topic_distribution, num_topics=5):\n",
    "    # Sort the topics by probability and select the top ones\n",
    "    return sorted(topic_distribution, key=lambda x: x[1], reverse=True)[:num_topics]\n",
    "\n",
    "df['top_topics'] = df['topic_distribution'].apply(lambda x: get_top_topics(x, 11 - 1))\n",
    "\n",
    "def label_topics(topic_list, lda_model):\n",
    "    labels = []\n",
    "    for topic_id, _ in topic_list:\n",
    "        # Get the top words in the topic\n",
    "        words = lda_model.show_topic(topic_id, 5)\n",
    "        # Create a label (e.g., by joining the top words)\n",
    "        label = [word for word, prob in words]\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def topicise(labels, label_dict):\n",
    "    topics = []\n",
    "\n",
    "    for topic_list in labels:\n",
    "        for key, value in label_dict.items():\n",
    "            if set(topic_list) == set(value):\n",
    "                topics.append(key)\n",
    "\n",
    "    return topics\n",
    "\n",
    "label_dict = {\n",
    "    'Quality of Food & Service' : ['service', 'food', 'restaurant', 'good', 'great'],\n",
    "    'French Dining Experience' : ['dinner', 'meal', 'french', 'reservation', 'little'],\n",
    "    'Atmosphere' : ['speak', 'dining', 'menu', 'experience', 'soup'],\n",
    "    'Price' : ['course', 'table', 'thing', 'life', 'party'],\n",
    "    'Special Occasions' : ['birthday', 'time', 'family', 'really', 'warm'],\n",
    "    'Ambience' : ['experience', 'overall', 'kiss', 'attentive', 'fantastic'],\n",
    "    'Dining Experience' : ['experience', 'overall', 'kiss', 'attentive', 'fantastic'],\n",
    "    'Staff' : ['year', 'last', 'time', 'first', 'second'],\n",
    "    'Menu' : ['atmosphere', 'area', 'bit', 'high', 'mummy'],\n",
    "    'Drinks' : ['way', 'incredible', 'class', 'wall', 'mood'] \n",
    "}\n",
    "\n",
    "df['top_topic_labels'] = df['top_topics'].apply(lambda x: label_topics(x, lda_model))\n",
    "df['topics'] = df['top_topic_labels'].apply(lambda x: topicise(x, label_dict))\n",
    "df.drop(columns=['topic_distribution', 'top_topics'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF & Classical ML (BM25) - Supervised Learning\n",
    "\n",
    "# TD-IDF - Use it for sentiment analysis\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform your review data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['tokens'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# BM25 - use it for recommendation and search engine\n",
    "\n",
    "# Create a BM25 vectorizer\n",
    "bm25_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
    "\n",
    "# Fit and transform your review data\n",
    "bm25_matrix = bm25_vectorizer.fit_transform(df['tokens'].apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Hugging face sentiment analysis - to modify as this is from a video!\n",
    "\n",
    "tokeniser = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "\n",
    "tokens = tokeniser.encode('It was great, I will come back again.', return_tensors=\"pt\")\n",
    "result = model(tokens)\n",
    "result.logits\n",
    "int(torch.argmax(result.logits))+1\n",
    "\n",
    "def extract_embeddings(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings[0].numpy()  # Extract embeddings for the first (and only) token\n",
    "\n",
    "def sentiment_score(review):\n",
    "    tokens = tokeniser.encode(review, return_tensors=\"pt\")\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "example_sentence = 'It was great, I will come back again.'\n",
    "embeddings = extract_embeddings(example_sentence)\n",
    "\n",
    "def write_embeddings_to_tensorboard(embeddings, output_dir):\n",
    "    # Create a TensorFlow summary writer\n",
    "    writer = tf.summary.create_file_writer(output_dir)\n",
    "\n",
    "    # Create a projector configuration\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "\n",
    "    # Assign the embeddings and their metadata\n",
    "    embedding.tensor_name = \"word_embeddings\"\n",
    "    embedding.metadata_path = \"metadata.tsv\"\n",
    "\n",
    "    with writer.as_default():\n",
    "        # Write embeddings\n",
    "        tf.summary.tensor(\"word_embeddings\", embeddings, step=0)\n",
    "\n",
    "    # Write metadata (words)\n",
    "    with open(output_dir + \"/metadata.tsv\", 'w', encoding='utf-8') as file:\n",
    "        file.write(\"Word\\n\")\n",
    "        for word in example_sentence.split():\n",
    "            file.write(word + \"\\n\")\n",
    "\n",
    "# Write embeddings to a directory for TensorBoard\n",
    "output_directory = \"tensorboard_embeddings\"\n",
    "write_embeddings_to_tensorboard(embeddings, output_directory)\n",
    "\n",
    "df['sentiment'] = df['text'].apply(lambda x: sentiment_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 16:33:50.937 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/alexandrecogordan/miniconda3/envs/tensorflow/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "def resize_image(image_path, width, height):\n",
    "    image = Image.open(image_path)\n",
    "    resized_image = image.resize((width, height))\n",
    "    return resized_image\n",
    "\n",
    "st.set_page_config(page_title=\"Gastonomy\", page_icon=\"üçΩÔ∏è\", layout=\"wide\")\n",
    "    \n",
    "st.sidebar.markdown(\"Select a city and a restaurant to generate a review.\")\n",
    "city = st.sidebar.selectbox(\"City\", sorted(df['location'].unique()))\n",
    "\n",
    "# Dictionary mapping city names to image filenames\n",
    "city_images = {\n",
    "    'New Orleans': 'resources/new-orleans.jpg',\n",
    "    'New York City': 'resources/new-york.jpg',\n",
    "    'Chicago': 'resources/chicago.jpg',\n",
    "    'Los Angeles': 'resources/los-angeles.jpg',\n",
    "    'San Francisco': 'resources/san-francisco.jpg',\n",
    "    'Philadelphia': 'resources/philadelphia.jpg',\n",
    "    'Las Vegas': 'resources/las-vegas.jpg',\n",
    "    'Houston': 'resources/houston.jpg',\n",
    "    'Phoenix': 'resources/phoenix.jpg',\n",
    "    'Miami': 'resources/miami.jpg'\n",
    "}\n",
    "\n",
    "# Display image based on selected city\n",
    "if city in city_images:\n",
    "    image_filename = city_images[city]\n",
    "    resized_image = resize_image(image_filename, 1920, 1080)\n",
    "    st.image(resized_image, caption=city)\n",
    "else:\n",
    "    st.write(\"Image not found for selected city.\")\n",
    "\n",
    "st.title(\"Restaurant Review Analysis\")\n",
    "\n",
    "st.header(\"Quel sont les aspects les plus importants pour vous dans un restaurant?\")\n",
    "topics = st.multiselect(\"Choisissez vos aspects\", sorted(label_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire: Faire choisir a l'utilisateur un ou des topics qu'il aimerait aborder. (S'il est interesse par le food quality par exemple on lui recommandera un restaurant avec une tres bonne food quality - peux-t-on recuperer les restaurants qui correspondent aux avis?).\n",
    "\n",
    "Montrer aussi les topics principaux les plus importants pour les resturants francais de chaque ville\n",
    "\n",
    "Later on, maybe use these topics to enhance the importance of them in summarised reviews.\n",
    "\n",
    "What I suggest is this: Topics principaux par villes. On demande a l'utilisateur de choisir ce qu'il prefere a travers un chatbot et ensuite on trouve les restaurants avec les meilleurs topics et de ce resturant on montre aussi ses meilleurs atouts avec les topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
